{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vuda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "print(nltk.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 4\n",
    "FRAC_SAMPLE = 0.01\n",
    "MAX_LENGTH_ARTICLE = 512\n",
    "MIN_LENGTH_ARTICLE = 50\n",
    "MAX_LENGTH_SUMMARY = 128\n",
    "MIN_LENGTH_SUMMARY = 20\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_CYCLES = 3\n",
    "MAX_PLATEAU_COUNT = 5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "model_dir = \"../Model\"\n",
    "datafilter = \"../dataft\"\n",
    "os.makedirs(datafilter, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "# validation_data = pd.read_csv(\"../dataset/validation.csv\")\n",
    "# test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "# # add col\n",
    "# train_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "# validation_data.rename(columns={\"highlights\": \"summaries\",\"article\":\"articles\"}, inplace=True)\n",
    "# test_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "\n",
    "# train_data[\"article_word_count\"] = train_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "# train_data[\"summary_word_count\"] = train_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# validation_data[\"article_word_count\"] = validation_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "# validation_data[\"summary_word_count\"] = validation_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# test_data[\"article_word_count\"] = test_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "# test_data[\"summary_word_count\"] = test_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# # filter range\n",
    "# train_data = train_data[\n",
    "#     (train_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "#     (train_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "#     (train_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "#     (train_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "# ]\n",
    "\n",
    "# validation_data = validation_data[\n",
    "#     (validation_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "#     (validation_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "#     (validation_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "#     (validation_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "# ]\n",
    "# test_data = test_data[\n",
    "#     (test_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "#     (test_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "#     (test_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "#     (test_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "# ]\n",
    "\n",
    "# train_sample = train_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "# validation_sample = validation_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "# test_sample = test_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "# train_sample.info()\n",
    "# print(\"\\n\")\n",
    "# validation_sample.info()\n",
    "# train_sample.to_csv(os.path.join(datafilter,\"train_sample.csv\"), index=False)\n",
    "# test_sample.to_csv(os.path.join(datafilter,\"test_sample.csv\"), index=False)\n",
    "# validation_sample.to_csv(os.path.join(datafilter,\"validation_sample.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenize(\"A dog. in a 'tree with 5.3% rate drop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 960 entries, 0 to 959\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  960 non-null    object\n",
      " 1   articles            960 non-null    object\n",
      " 2   summaries           960 non-null    object\n",
      " 3   article_word_count  960 non-null    int64 \n",
      " 4   summary_word_count  960 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 37.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sample = pd.read_csv(\"../dataft/train_sample.csv\")\n",
    "validation_sample = pd.read_csv(\"../dataft/validation_sample.csv\")\n",
    "test_sample = pd.read_csv(\"../dataft/test_sample.csv\")\n",
    "train_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(100004, 54, padding_idx=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP_K = 100000\n",
    "EMBEDDING_FILE = \"../Embedding/glove.6B.50d.txt\"\n",
    "\n",
    "vocab, embeddings = [], []\n",
    "\n",
    "with open(EMBEDDING_FILE, 'rt', encoding='utf-8') as ef:\n",
    "    for i, line in enumerate(ef):\n",
    "        if i >= TOP_K:\n",
    "            break\n",
    "        split_line = line.strip().split(' ')\n",
    "        i_word = split_line[0]\n",
    "        i_embeddings = [float(val) for val in split_line[1:]]\n",
    "        i_embeddings.extend([0.0, 0.0, 0.0, 0.0])  # để dành cho token đặc biệt\n",
    "        vocab.append(i_word)\n",
    "        embeddings.append(i_embeddings)\n",
    "\n",
    "\n",
    "embs_npa = np.array(embeddings)\n",
    "\n",
    "unk_embedding = np.mean(embs_npa, axis=0).tolist()\n",
    "\n",
    "dim = embs_npa.shape[1]\n",
    "sos_embedding = [0.0] * dim\n",
    "sos_embedding[-3] = 1.0\n",
    "eos_embedding = [0.0] * dim\n",
    "eos_embedding[-2] = 1.0\n",
    "pad_embedding = [0.0] * dim\n",
    "pad_embedding[-4] = 1.0\n",
    "# unk_embedding = [0.0] * dim\n",
    "# unk_embedding[-1] = 1.0\n",
    "\n",
    "# Update vocab and embeddings\n",
    "vocab = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"] + vocab\n",
    "embeddings = [pad_embedding, sos_embedding,\n",
    "              eos_embedding, unk_embedding] + embeddings\n",
    "\n",
    "vocab_npa = np.array(vocab)\n",
    "embs_npa = np.array(embeddings)\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "def preclean_text(text):\n",
    "    text = re.sub(r\"\\s'([a-zA-Z])\", r\" '\\1\", text)\n",
    "\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "\n",
    "stoi_dict = {word: idx for idx, word in enumerate(vocab_npa)}\n",
    "_unk_idx = stoi_dict[\"<UNK>\"]\n",
    "itos_dict = {idx: word for idx, word in enumerate(vocab_npa)}\n",
    "\n",
    "def stoi(string, stoi_dict=stoi_dict):\n",
    "    return stoi_dict.get(string, _unk_idx)\n",
    "\n",
    "def itos(idx, itos_dict=itos_dict):\n",
    "    return itos_dict.get(idx)\n",
    "\n",
    "def revert_to_text(lst):\n",
    "    if hasattr(lst, 'tolist'):  # works for both torch.Tensor and np.ndarray\n",
    "        lst = lst.tolist()\n",
    "    return [str(itos(int(token))) for token in lst] \n",
    "\n",
    "\n",
    "def numericalize(text):\n",
    "    tokenized_text = tokenize(text)\n",
    "    return [\n",
    "        stoi(token)\n",
    "        for token in tokenized_text\n",
    "    ]\n",
    "\n",
    "print(embs_npa.shape[0])\n",
    "embedding_layer = torch.nn.Embedding.from_pretrained(torch.FloatTensor(embeddings),\n",
    "                                                     freeze=False,\n",
    "                                                     padding_idx=stoi(\"<PAD>\"))\n",
    "embedding_layer.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (100004, 54)\n",
      "<PAD> embedding last 4 dims: [1.0, 0.0, 0.0, 0.0]\n",
      "<SOS> embedding last 4 dims: [0.0, 1.0, 0.0, 0.0]\n",
      "Word 'the' embedding last 4 dims: [0.03656563577138949, -0.18582784663417096, -0.06781056216307739, -0.040585373685092956, -0.07301668493291918, 0.016044644258671987, 0.1372867005388796, -0.07036971064271462, -0.10438737653424474, 0.11584013095302573, 0.03797717741161136, 0.02782290565024015, 0.042134458545775105, 0.006004885678202956, -0.04811175801439264, 0.01938162005008408, -0.06738358746789967, 0.07091858680646929, 0.0485902582917709, 0.12120493521288776, -0.11500593603289162, 0.003967934351382163, 0.05070292498116329, 0.005906024159269963, 0.06472339142162035, 0.022294008330708867, 0.009735554614555037, 0.08725065600012115, -0.042772991751960865, -0.07584176364629841, 0.03525691425508773, 0.04915543195526088, 0.05126815078068994, 0.1762973806305546, 0.02469765032816606, 0.01257729470118004, -0.015610369137945711, 0.016562756680375525, 0.03602458095111814, 0.10879419304109057, 0.04508684491707534, 0.006128239519379899, -0.05675747442860022, 0.10992612823451169, -0.049369772987440975, -0.05613294116998497, 0.12215405517406071, 0.03984780185007495, 0.004019756383222037, -0.08868347836366922, 0.0, 0.0, 0.0, 0.0]\n",
      "['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_npa)\n",
    "print(\"Embedding shape:\", np.array(embeddings).shape) \n",
    "print(\"<PAD> embedding last 4 dims:\", embeddings[stoi(\"<PAD>\")][-4:])\n",
    "print(\"<SOS> embedding last 4 dims:\", embeddings[stoi(\"<SOS>\")][-4:])\n",
    "print(\"Word 'the' embedding last 4 dims:\", embeddings[stoi(\"5.3%\")])\n",
    "print(revert_to_text(torch.tensor([0, 1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A word not in dict:  finlason\n",
      "\n",
      "Train Vocabulary Coverage:\n",
      "- Unique words: 28137\n",
      "- Exist in dict: 21586\n",
      "- Outside the dict: 6551\n",
      "- Coverage rate: 76.72%\n",
      "A word not in dict:  police-related\n",
      "\n",
      "Validation Vocabulary Coverage:\n",
      "- Unique words: 4104\n",
      "- Exist in dict: 3718\n",
      "- Outside the dict: 386\n",
      "- Coverage rate: 90.59%\n",
      "A word not in dict:  i'am\n",
      "\n",
      "Test Vocabulary Coverage:\n",
      "- Unique words: 3707\n",
      "- Exist in dict: 3368\n",
      "- Outside the dict: 339\n",
      "- Coverage rate: 90.86%\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def analyze_vocab_coverage(sample_data, stoi_dict):\n",
    "    # Đếm tần suất từ duy nhất\n",
    "    word_freq = defaultdict(int)\n",
    "\n",
    "    for text in sample_data['articles'] + sample_data['summaries']:\n",
    "        tokens = tokenize(text)\n",
    "        for token in tokens:\n",
    "            word_freq[token] += 1\n",
    "\n",
    "    # Phân loại từ vào known / unknown\n",
    "    known_words = set()\n",
    "    unknown_words = set()\n",
    "\n",
    "    for word in word_freq:\n",
    "        if word in stoi_dict:\n",
    "            known_words.add(word)\n",
    "        else:\n",
    "            unknown_words.add(word)\n",
    "\n",
    "    total_unique_words = len(known_words) + len(unknown_words)\n",
    "    coverage = len(known_words) / total_unique_words * 100 if total_unique_words > 0 else 0.0\n",
    "    print(\"A word not in dict: \", random.choice(list(unknown_words)))\n",
    "    return {\n",
    "        'total_unique_words': total_unique_words,\n",
    "        'known_unique_words': len(known_words),\n",
    "        'unknown_unique_words': len(unknown_words),\n",
    "        'coverage_percentage': coverage,\n",
    "    }\n",
    "def print_vocab_stats(name, stats):\n",
    "    print(f\"\\n{name} Vocabulary Coverage:\")\n",
    "    print(f\"- Unique words: {stats['total_unique_words']}\")\n",
    "    print(f\"- Exist in dict: {stats['known_unique_words']}\")\n",
    "    print(f\"- Outside the dict: {stats['unknown_unique_words']}\")\n",
    "    print(f\"- Coverage rate: {stats['coverage_percentage']:.2f}%\")\n",
    "\n",
    "print_vocab_stats(\"Train\", analyze_vocab_coverage(train_sample, stoi_dict))\n",
    "print_vocab_stats(\"Validation\", analyze_vocab_coverage(validation_sample, stoi_dict))\n",
    "print_vocab_stats(\"Test\", analyze_vocab_coverage(test_sample, stoi_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, articles, summaries, stoi, max_len_article=MAX_LENGTH_ARTICLE, max_len_summary=MAX_LENGTH_SUMMARY):\n",
    "        self.articles = articles  # List of articles\n",
    "        self.summaries = summaries  # List of summaries\n",
    "        self.stoi = stoi \n",
    "        self.pad_idx = stoi(\"<PAD>\")\n",
    "        self.sos_idx = stoi(\"<SOS>\")\n",
    "        self.eos_idx = stoi(\"<EOS>\")\n",
    "        \n",
    "        self.max_len_article = max_len_article \n",
    "        self.max_len_summary = max_len_summary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def process_text(text, max_len):\n",
    "            tokens = [self.sos_idx] + [self.stoi(w) for w in text.split()] + [self.eos_idx]  # Tokenize and add SOS/EOS\n",
    "            tokens = tokens[:max_len] + [self.pad_idx] * (max_len - len(tokens))  # Pad to max length\n",
    "            return torch.tensor(tokens), len(tokens)\n",
    "\n",
    "        article_tokens, article_len = process_text(self.articles[idx], self.max_len_article)\n",
    "        summary_tokens, summary_len = process_text(self.summaries[idx], self.max_len_summary)\n",
    "        \n",
    "        return {\n",
    "            'article': article_tokens,  # Encoded article\n",
    "            'article_len': torch.tensor(article_len),\n",
    "            'summary': summary_tokens,  # Encoded summary\n",
    "            'summary_len': torch.tensor(summary_len)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Batch is list os the dict {'article': ..., 'summary': ...}\n",
    "    return {\n",
    "        'article': torch.stack([item['article'] for item in batch]),\n",
    "        'article_len': torch.tensor([item['article_len'] for item in batch]),\n",
    "        'summary': torch.stack([item['summary'] for item in batch]),\n",
    "        'summary_len': torch.tensor([item['summary_len'] for item in batch])\n",
    "    }\n",
    "\n",
    "# DataLoader setup\n",
    "\n",
    "torch.set_printoptions(profile=\"default\")\n",
    "train_dataset = Seq2SeqDataset(train_sample['articles'].tolist(), train_sample['summaries'].tolist(), stoi)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "validation_dataset= Seq2SeqDataset(validation_sample['articles'].tolist(), validation_sample['summaries'].tolist(), stoi)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset= Seq2SeqDataset(test_sample['articles'].tolist(), test_sample['summaries'].tolist(), stoi)\n",
    "test_loader = DataLoader(test_sample, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# torch.set_printoptions(profile=\"full\")\n",
    "# print(train_dataset[268][\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding.embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=False  # Unidirectional\n",
    "        )\n",
    "        self.hidden_dim = hidden_dim\n",
    "    \n",
    "    def forward(self, x, seq_lens):\n",
    "        x = self.embedding(x) \n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            input=x,\n",
    "            lengths=seq_lens.cpu(), \n",
    "            batch_first=True,\n",
    "            enforce_sorted=False \n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.lstm(packed)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # hidden shape: [1, batch_size, hidden_dim]\n",
    "        return output, hidden.squeeze(0)  # Return only hidden state for decoder init\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        # hidden: [batch_size, hidden_dim]\n",
    "        # encoder_outputs: [batch_size, seq_len, hidden_dim]\n",
    "        # mask: [batch_size, seq_len]\n",
    "        \n",
    "        hidden = hidden.unsqueeze(1).repeat(1, encoder_outputs.size(1), 1)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch_size, seq_len, hidden_dim]\n",
    "        attention = self.v(energy).squeeze(2)  # [batch_size, seq_len]\n",
    "        \n",
    "        attention = attention.masked_fill(mask == 0, -1e10)  # Apply mask to padded positions\n",
    "        return F.softmax(attention, dim=1)  # Normalized attention weights\n",
    "\n",
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.attention = SimpleAttention(hidden_dim)\n",
    "        self.lstm = nn.LSTMCell(self.embedding.embedding_dim + hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, vocab_size)  # hidden + context\n",
    "        \n",
    "    def forward(self, x, hidden, cell, encoder_outputs, mask):\n",
    "        # x: [batch_size] (long tensor)\n",
    "        # hidden, cell: [batch_size, hidden_dim]\n",
    "        # encoder_outputs: [batch_size, seq_len, hidden_dim]\n",
    "        # mask: [batch_size, seq_len]\n",
    "        \n",
    "        x = x.unsqueeze(0) if x.dim() == 0 else x  # handle single example\n",
    "        embedded = self.embedding(x)  # [batch_size, emb_dim]\n",
    "        \n",
    "        # Attention\n",
    "        attn_weights = self.attention(hidden, encoder_outputs, mask)  # [batch_size, seq_len]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # LSTM step\n",
    "        lstm_input = torch.cat((embedded, context), dim=1)  # [batch_size, emb_dim + hidden_dim]\n",
    "        hidden, cell = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        # Output prediction\n",
    "        output = torch.cat((hidden, context), dim=1)  # [batch_size, hidden_dim * 2]\n",
    "        output = self.fc_out(output)  # [batch_size, vocab_size]\n",
    "        \n",
    "        return output, hidden, cell, attn_weights\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim, vocab_size, pad_idx):\n",
    "        super().__init__()\n",
    "        self.encoder = SimpleEncoder(embedding_layer, hidden_dim)\n",
    "        self.decoder = SimpleDecoder(embedding_layer, hidden_dim, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.pad_idx = pad_idx\n",
    "        self.start_idx = stoi(\"<SOS>\")\n",
    "    \n",
    "    def create_mask(self, src):\n",
    "        # src: [batch_size, seq_len]\n",
    "        return (src != self.pad_idx)\n",
    "    \n",
    "    def forward(self, src, src_lens, trg=None, teacher_forcing_ratio=0.5, max_len=50):\n",
    "        # src: [batch_size, src_len]\n",
    "        # src_lens: [batch_size]\n",
    "        # trg: [batch_size, trg_len] if training, None if inference\n",
    "        \n",
    "        batch_size = src.size(0)\n",
    "        max_len = trg.size(1) if trg is not None else max_len\n",
    "        \n",
    "        # Encoder forward\n",
    "        encoder_outputs, hidden = self.encoder(src, src_lens)  # encoder_outputs: [batch_size, src_len, hidden_dim]\n",
    "        cell = torch.zeros_like(hidden)  # Initialize cell state for decoder\n",
    "        \n",
    "        # Initialize outputs tensor\n",
    "        outputs = torch.zeros(batch_size, max_len, self.vocab_size).to(src.device)\n",
    "        \n",
    "        # First input is <SOS> token\n",
    "        input = torch.full((batch_size,), self.start_idx, dtype=torch.long, device=src.device)\n",
    "        \n",
    "        # Create mask for attention\n",
    "        mask = self.create_mask(src)\n",
    "        \n",
    "        for t in range(max_len):\n",
    "            output, hidden, cell, _ = self.decoder(\n",
    "                input, hidden, cell, encoder_outputs, mask\n",
    "            )\n",
    "            \n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            # Decide whether to use teacher forcing\n",
    "            if trg is not None and random.random() < teacher_forcing_ratio:\n",
    "                input = trg[:, t]\n",
    "            else:\n",
    "                input = output.argmax(1)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory allocated: 20.60 MB\n",
      "GPU Memory reserved: 22.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU Memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "print(f\"GPU Memory reserved: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([100004, 54])\n",
      "Vocab size: 100004\n",
      "Model architecture:\n",
      "Seq2SeqModel(\n",
      "  (encoder): SimpleEncoder(\n",
      "    (embedding): Embedding(100004, 54, padding_idx=0)\n",
      "    (lstm): LSTM(54, 128, batch_first=True)\n",
      "  )\n",
      "  (decoder): SimpleDecoder(\n",
      "    (embedding): Embedding(100004, 54, padding_idx=0)\n",
      "    (attention): SimpleAttention(\n",
      "      (attn): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
      "    )\n",
      "    (lstm): LSTMCell(182, 128)\n",
      "    (fc_out): Linear(in_features=256, out_features=100004, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Seq2SeqModel(\n",
    "    embedding_layer=embedding_layer,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    vocab_size=vocab_size,\n",
    "    pad_idx=stoi(\"<PAD>\")  # Make sure this matches your vocabulary\n",
    ").to(device)\n",
    "print(\"Embedding shape:\", torch.FloatTensor(embeddings).shape)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvubkk67\u001b[0m (\u001b[33mvubkk67-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vuda/Text-Summarization/Abstractive/wandb/run-20250408_174100-riw5vp6r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/riw5vp6r' target=\"_blank\">seq2seq-20250408-174059</a></strong> to <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/riw5vp6r' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/riw5vp6r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/riw5vp6r?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8f60f3fc50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Seq2Seq-Summarization\",\n",
    "    name=f\"seq2seq-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"model\": \"Seq2Seq-LSTM\",\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"teacher_forcing_ratio\": 1.0,\n",
    "        \"vocab_size\": len(vocab)\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_warmup_decay(step, warmup_steps, total_steps):\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / (warmup_steps + 1)\n",
    "    else:\n",
    "        return max(1e-7, (total_steps - step) / (total_steps - warmup_steps))\n",
    "\n",
    "\n",
    "def warmup_cosine_with_restarts(step, warmup_steps, total_steps, num_cycles=1):\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / (warmup_steps + 1)\n",
    "    else:\n",
    "        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "        cycle_progress = progress * num_cycles % 1\n",
    "        return max(1e-7, 0.5 * (1 + math.cos(math.pi * cycle_progress)))\n",
    "\n",
    "\n",
    "\n",
    "def get_scheduler(\n",
    "    optimizer, total_steps, warmup_steps, num_cycles=None, types='warmup_cosine_with_restarts'\n",
    "):\n",
    "    if types == 'warmup_cosine_with_restarts':\n",
    "        assert num_cycles != None, 'must specify num_cycles when types=\"warmup_cosine_with_restarts\"'\n",
    "        return torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda step: warmup_cosine_with_restarts(\n",
    "                step, warmup_steps, total_steps, num_cycles=num_cycles)\n",
    "        )\n",
    "    elif types == 'linear_warmup_decay':\n",
    "        return torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda step: linear_warmup_decay(step, warmup_steps, total_steps)\n",
    "        )\n",
    "    else:\n",
    "        raise Exception('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887dfda96e6a41d4b9ff287f8bfaf1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859aaf7519ed40dabd05d896f661ad94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 7.3393 | Val Loss: 5.8663 | LR: 0.001671 | Time: 243.64s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffc41bdc7be472690b98a034ee3e1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de43063853a439fbc76c16133776f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 5.8436 | Val Loss: 5.8091 | LR: 0.003336 | Time: 243.47s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53e0f12411849cca71b1df32e629d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef15b36a765481f8cf544bfd1f5d394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 5.6884 | Val Loss: 5.7899 | LR: 0.005000 | Time: 242.80s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ff7853529f41769c440a506077239d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f016ccf641c34f9b9b8ae3e4af00612d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 5.5652 | Val Loss: 5.8222 | LR: 0.004849 | Time: 242.48s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f12c3635a974152b66daa14f35357eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d0b0fd14864fa9abe1c9f8c4c3c66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 5.4499 | Val Loss: 5.7620 | LR: 0.004415 | Time: 242.69s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57804070f695454fb6569b37d81ec1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd3c213de25483e9fa9863281bbb797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 5.3597 | Val Loss: 5.6858 | LR: 0.003750 | Time: 243.40s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeee5a383534107a198f19c15168f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f2a541bfae40adb4cb068bb2289bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 5.2770 | Val Loss: 5.6535 | LR: 0.002934 | Time: 247.77s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56b4c65acf14bad945b480b0a70f628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fffc1be46d4b0c834a66764f803937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 5.1919 | Val Loss: 5.6434 | LR: 0.002066 | Time: 245.51s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f8e2ed7f95418189f62a1cd43dee36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def train_model(model, train_loader, optimizer, criterion, device, lr_scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        src = batch['article'].to(device)\n",
    "        src_lens = batch['article_len'].to(device)\n",
    "        trg = batch['summary'].to(device)\n",
    "        \n",
    "        # Forward pass with teacher forcing\n",
    "        outputs = model(src, src_lens, trg=trg, teacher_forcing_ratio=0.5)  # Using 50% teacher forcing\n",
    "        \n",
    "        # Reshape outputs and targets for loss calculation\n",
    "        # outputs shape: [batch_size, trg_len, vocab_size]\n",
    "        # trg shape: [batch_size, trg_len]\n",
    "        outputs = outputs[:, 1:].reshape(-1, outputs.size(-1))  # Skip <SOS> token\n",
    "        trg = trg[:, 1:].reshape(-1)  # Skip <SOS> token\n",
    "        \n",
    "        loss = criterion(outputs, trg)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            src = batch['article'].to(device)\n",
    "            src_lens = batch['article_len'].to(device)\n",
    "            trg = batch['summary'].to(device)\n",
    "            \n",
    "            # Forward pass without teacher forcing (ratio=0)\n",
    "            outputs = model(src, src_lens, trg=trg, teacher_forcing_ratio=0)\n",
    "            \n",
    "            # Reshape outputs and targets\n",
    "            outputs = outputs[:, 1:].reshape(-1, outputs.size(-1))\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(outputs, trg)\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Save best Model\n",
    "best_model_path = os.path.join(model_dir, \"best_model_300.pth\")\n",
    "\n",
    "# 4. Train loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi(\"<PAD>\"))\n",
    "best_val_loss = float('inf')\n",
    "# Initialize learning rate scheduler\n",
    "total_steps = NUM_EPOCHS * len(train_loader)\n",
    "warmup_steps = int(0.1 * total_steps)  # 10% of total steps for warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    optimizer, \n",
    "    total_steps=total_steps,\n",
    "    warmup_steps=warmup_steps,\n",
    "    num_cycles=NUM_CYCLES\n",
    ")\n",
    "plateau_count = 0\n",
    "wandb.watch(model)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion, device,lr_scheduler)\n",
    "    \n",
    "    # Eval\n",
    "    val_loss = evaluate(model, validation_loader, criterion, device)\n",
    "    \n",
    "    current_lr = lr_scheduler.get_last_lr()[0] if lr_scheduler else LEARNING_RATE\n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch+1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"best_val_loss\": best_val_loss, \n",
    "        \"lr\": current_lr\n",
    "    })\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        plateau_count = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler_state_dict': lr_scheduler.state_dict() if lr_scheduler else None,\n",
    "        }, best_model_path)\n",
    "    else:\n",
    "        plateau_count += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"LR: {current_lr:.6f} | \"\n",
    "          f\"Time: {time.time()-start_time:.2f}s\")\n",
    "    \n",
    "    # Early stopping if validation loss doesn't improve\n",
    "    if plateau_count >= MAX_PLATEAU_COUNT:\n",
    "        print(f\"Validation loss hasn't improved for {MAX_PLATEAU_COUNT} epochs. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# Kết thúc W&B\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
