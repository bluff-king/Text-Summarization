{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os \n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from rouge import Rouge\n",
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 8\n",
    "FRAC_SAMPLE = 0.01\n",
    "MAX_LENGTH_ARTICLE = 512\n",
    "MIN_LENGTH_ARTICLE = 50\n",
    "MAX_LENGTH_SUMMARY = 128\n",
    "MIN_LENGTH_SUMMARY = 20\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_PLATEAU_COUNT = 5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_CYCLES = 5\n",
    "\n",
    "\n",
    "model_dir = \"../Model\"\n",
    "datafilter = \"../dataft\"\n",
    "save_dir = \"fine_tuned_t5_small\"\n",
    "output_path = os.path.join(datafilter, \"test_pred_t5_small_0.csv\")\n",
    "os.makedirs(datafilter, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "# validation_data = pd.read_csv(\"../dataset/validation.csv\")\n",
    "# test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "# # add col\n",
    "# train_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "# validation_data.rename(columns={\"highlights\": \"summaries\",\"article\":\"articles\"}, inplace=True)\n",
    "# test_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "\n",
    "# train_data[\"article_word_count\"] = train_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "# train_data[\"summary_word_count\"] = train_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# validation_data[\"article_word_count\"] = validation_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "# validation_data[\"summary_word_count\"] = validation_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# test_data[\"article_word_count\"] = test_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "# test_data[\"summary_word_count\"] = test_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# # filter range\n",
    "# train_data = train_data[\n",
    "#     (train_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "#     (train_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "#     (train_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "#     (train_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "# ]\n",
    "\n",
    "# validation_data = validation_data[\n",
    "#     (validation_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "#     (validation_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "#     (validation_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "#     (validation_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "# ]\n",
    "# test_data = test_data[\n",
    "#     (test_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "#     (test_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "#     (test_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "#     (test_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "# ]\n",
    "\n",
    "# train_sample = train_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "# validation_sample = validation_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "# test_sample = test_data.sample(frac=1, random_state=1)\n",
    "# train_sample.info()\n",
    "# print(\"\\n\")\n",
    "# validation_sample.info()\n",
    "# train_sample.to_csv(os.path.join(datafilter,\"train_sample.csv\"), index=False)\n",
    "# test_sample.to_csv(os.path.join(datafilter,\"test_sample.csv\"), index=False)\n",
    "# validation_sample.to_csv(os.path.join(datafilter,\"validation_sample.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 960 entries, 0 to 959\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  960 non-null    object\n",
      " 1   articles            960 non-null    object\n",
      " 2   summaries           960 non-null    object\n",
      " 3   article_word_count  960 non-null    int64 \n",
      " 4   summary_word_count  960 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 37.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  42 non-null     object\n",
      " 1   articles            42 non-null     object\n",
      " 2   summaries           42 non-null     object\n",
      " 3   article_word_count  42 non-null     int64 \n",
      " 4   summary_word_count  42 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 1.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sample = pd.read_csv(\"../dataft/train_sample.csv\")\n",
    "validation_sample = pd.read_csv(\"../dataft/validation_sample.csv\")\n",
    "test_sample = pd.read_csv(\"../dataft/test_sample.csv\")\n",
    "train_sample.info()\n",
    "test_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_length=MAX_LENGTH_ARTICLE, max_output_length=MAX_LENGTH_SUMMARY):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        article = self.data.iloc[index][\"articles\"]\n",
    "        summary = self.data.iloc[index][\"summaries\"]\n",
    "        \n",
    "        # T5 need prefix:\n",
    "        input_text = \"summarize: \" + article\n",
    "        inputs = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        outputs = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=self.max_output_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": inputs.input_ids.squeeze(),\n",
    "            \"attention_mask\": inputs.attention_mask.squeeze(),\n",
    "            \"labels\": outputs.input_ids.squeeze()\n",
    "        }\n",
    "train_df = train_sample\n",
    "val_df = validation_sample\n",
    "test_df = test_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummarizationDataset(train_df, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_df, tokenizer)\n",
    "test_dataset = SummarizationDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n",
    "    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n",
    "    labels = torch.stack([item[\"labels\"] for item in batch])\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "num_training_steps = len(train_loader) * NUM_EPOCHS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.2 * num_training_steps),\n",
    "    num_training_steps=num_training_steps,\n",
    "    num_cycles=NUM_CYCLES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvubkk67\u001b[0m (\u001b[33mvubkk67-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vuda/Text-Summarization/Abstractive/wandb/run-20250509_132137-bu4d87uu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/bu4d87uu' target=\"_blank\">t5small-20250509-132136</a></strong> to <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/bu4d87uu' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/bu4d87uu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/bu4d87uu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7216213e90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Finetune-Summarization\",\n",
    "    name=f\"t5small-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"model\": \"t5-small\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"num_cycles\": NUM_CYCLES,\n",
    "        \"data_ratio\": FRAC_SAMPLE,\n",
    "        \"warm_up\": \"Cosine\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c63b8631ef24033a013578b0e5eca44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082fac7e6fc4439d900b3ee0336f3c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 1\n",
      "Epoch 01 | Train Loss: 10.6276 | Val Loss: 9.4441 | LR: 0.000002 | Time: 115.44s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8bacb8854a43e097fff1b95688cdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9378dbd9d3740c6bafc45eb4adfde9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 2\n",
      "Epoch 02 | Train Loss: 9.1191 | Val Loss: 7.3647 | LR: 0.000003 | Time: 118.83s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096100a5ac3e4192b7597d89df427d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4a5f3f3a404996b5e524cb9ad67f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 3\n",
      "Epoch 03 | Train Loss: 6.1366 | Val Loss: 3.8329 | LR: 0.000005 | Time: 118.67s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ece08e85b446419a7014b51c1cf1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8627a9dd9594b3b81a657e7174ff19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 4\n",
      "Epoch 04 | Train Loss: 2.8895 | Val Loss: 1.4977 | LR: 0.000007 | Time: 118.38s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4debf70bd443cc83450307ed008d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18aeb7f90c594bd98946de50d80f5806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 5\n",
      "Epoch 05 | Train Loss: 1.8569 | Val Loss: 1.2144 | LR: 0.000008 | Time: 119.77s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de892b9c72545d7ae8c12efbb44f723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac624143413c4308862c3c894838cd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 6\n",
      "Epoch 06 | Train Loss: 1.6044 | Val Loss: 1.1754 | LR: 0.000010 | Time: 117.34s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec18ddbba3b40c787b24cacf5e3c943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff8f571f2824fce8cdbc6d49637d577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 7\n",
      "Epoch 07 | Train Loss: 1.4568 | Val Loss: 1.1598 | LR: 0.000006 | Time: 117.51s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979e2b59c6e1479b8a0cf63fc5238bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9231b3dbaf1543cdbc7c3167b9ba10a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 8\n",
      "Epoch 08 | Train Loss: 1.3743 | Val Loss: 1.1545 | LR: 0.000001 | Time: 125.60s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1fbb56fda54de4bfb7a5e02aa9c65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5893330500bb4b2394656ab8f438c594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 9\n",
      "Epoch 09 | Train Loss: 1.3478 | Val Loss: 1.1538 | LR: 0.000001 | Time: 122.91s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3e204e2f8e4459abd4c1ff302fab58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a22e0640b734e94810fed6b9472ec96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 10\n",
      "Epoch 10 | Train Loss: 1.3266 | Val Loss: 1.1457 | LR: 0.000007 | Time: 116.22s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2f3b4dca3547a685f07f98b421edfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb4693291cc4499b166989bc4c9f315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 11\n",
      "Epoch 11 | Train Loss: 1.2315 | Val Loss: 1.1361 | LR: 0.000010 | Time: 116.68s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b17717897dd4d49b9304ba4ee57e10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca133222f1242dc89e3868fc6d5f3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 12\n",
      "Epoch 12 | Train Loss: 1.1349 | Val Loss: 1.1260 | LR: 0.000005 | Time: 117.41s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85311bcad2b94bfd832038e161fb58d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f50e74875646599d8cab348212a2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 13\n",
      "Epoch 13 | Train Loss: 1.1089 | Val Loss: 1.1232 | LR: 0.000000 | Time: 114.86s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1f6ca8954b4c1dbdf200227be75382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4976a51deb3e4b1092730668a39c1ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 14\n",
      "Epoch 14 | Train Loss: 1.1066 | Val Loss: 1.1224 | LR: 0.000002 | Time: 113.93s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38469aef74f64879b074185921c9e4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1657af682cd647cc9f23e4cde36e7d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 15\n",
      "Epoch 15 | Train Loss: 1.0896 | Val Loss: 1.1125 | LR: 0.000009 | Time: 113.44s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96032ef749b4497a9bc8ab3c7ec17da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e63a95a2b54dc288b217aa4fe47082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 16\n",
      "Epoch 16 | Train Loss: 1.0507 | Val Loss: 1.0955 | LR: 0.000009 | Time: 116.88s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449aeee49c9e41aa92d23a2f84a55197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff44c0e9061649ac8195e6d31c107ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 17\n",
      "Epoch 17 | Train Loss: 1.0265 | Val Loss: 1.0831 | LR: 0.000004 | Time: 121.02s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0740c980fdb74e5fafaa23aa4513b41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea313678d384046963863c39635fa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 18\n",
      "Epoch 18 | Train Loss: 1.0161 | Val Loss: 1.0808 | LR: 0.000000 | Time: 115.40s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec80e1ce4a624395ba5e35000cad27db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4149245cfb50406d91592fe2c16f79b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 19\n",
      "Epoch 19 | Train Loss: 1.0143 | Val Loss: 1.0786 | LR: 0.000004 | Time: 117.50s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10f99808ebb4eb0a54554413b3e4b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48042f0a8f084d3ea13aff8eb7636883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 20\n",
      "Epoch 20 | Train Loss: 1.0092 | Val Loss: 1.0647 | LR: 0.000009 | Time: 118.94s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e163c0f43542049897def76626d933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ac3750d19046f699ae9f4b39b98242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 21\n",
      "Epoch 21 | Train Loss: 0.9866 | Val Loss: 1.0497 | LR: 0.000009 | Time: 116.82s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e17c7f2ebcc4f03906301c1f83b9b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e355fc7008994694b2af70c1d377cf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 22\n",
      "Epoch 22 | Train Loss: 0.9675 | Val Loss: 1.0430 | LR: 0.000003 | Time: 116.96s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19f8b0226374f248f19259a1acdb81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09eb0b4d08724ca6bc132646be6de7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 23\n",
      "Epoch 23 | Train Loss: 0.9647 | Val Loss: 1.0420 | LR: 0.000000 | Time: 116.49s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91eddca19bf42f09ccd64ecd721de91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2610ff089bf4cfdb8e9392099e9bace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 24\n",
      "Epoch 24 | Train Loss: 0.9605 | Val Loss: 1.0395 | LR: 0.000005 | Time: 115.72s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef970e8dcf84619b475badf97ddbdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356ad7b1cf53493db8bd87b9191abfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 25\n",
      "Epoch 25 | Train Loss: 0.9540 | Val Loss: 1.0322 | LR: 0.000010 | Time: 117.43s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421d8db6d54a43caa857c9c6807aac2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875d10c1ab7c4caab7333d5c14fd76c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 26\n",
      "Epoch 26 | Train Loss: 0.9434 | Val Loss: 1.0253 | LR: 0.000007 | Time: 117.47s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d500e1f4ab864ba2b66af732ae18f1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626c248931a842508d8dc49600529526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 27\n",
      "Epoch 27 | Train Loss: 0.9342 | Val Loss: 1.0224 | LR: 0.000001 | Time: 118.19s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad9ee080a8f407cbe06163d39f229b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094749bd75174f0d9fc7a09b6a8dacaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 28\n",
      "Epoch 28 | Train Loss: 0.9299 | Val Loss: 1.0222 | LR: 0.000001 | Time: 117.50s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd753b7f66e4b1198e9ebb2b944a9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330039a2f67744659b4ba28dca5b782e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 29\n",
      "Epoch 29 | Train Loss: 0.9273 | Val Loss: 1.0201 | LR: 0.000006 | Time: 122.34s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fd28fcc8f0489fa8c163d9cf83fc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 [Train]:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d74fbc073a4bd7971cdb5bd7e4eaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_t5_small` at epoch 30\n",
      "Epoch 30 | Train Loss: 0.9209 | Val Loss: 1.0156 | LR: 0.000010 | Time: 116.57s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40c862444664117925c6c308e202ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.225 MB of 0.225 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td> █▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>▂▃▅▆▇█▅▁▂▆█▅▁▃▇█▄▁▄█▇▃▁▅█▆▂▁▅█</td></tr><tr><td>train_loss</td><td>█▇▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>1.02014</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.9209</td></tr><tr><td>val_loss</td><td>1.01561</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">t5small-20250509-132136</strong> at: <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/bu4d87uu' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/bu4d87uu</a><br/> View project at: <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250509_132137-bu4d87uu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float(\"inf\")\n",
    "plateau_count = 0\n",
    "wandb.watch(model)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    # W&B log\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"lr\": current_lr,\n",
    "        \"best_val_loss\": best_val_loss\n",
    "    })\n",
    "\n",
    "    # Save best model or increment plateau counter\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        plateau_count = 0  # Reset plateau counter\n",
    "        model.save_pretrained(save_dir)\n",
    "        tokenizer.save_pretrained(save_dir)\n",
    "        print(f\"Saved best model to `{save_dir}` at epoch {epoch+1}\")\n",
    "    else:\n",
    "        plateau_count += 1\n",
    "        print(f\"No improvement in val_loss. Plateau count: {plateau_count}/{MAX_PLATEAU_COUNT}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if plateau_count >= MAX_PLATEAU_COUNT:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1} due to {plateau_count} consecutive non-improvements.\")\n",
    "        break\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"LR: {current_lr:.6f} | \"\n",
    "        f\"Time: {time.time() - start_time:.2f}s\"\n",
    "    )\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(save_dir).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb8e3ebcb9442c1ab0b2cc2383af11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating summaries:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File has been saved at: ../dataft/test_pred_t5_small_0.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(test_loader, desc=\"Generating summaries\")):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        output_ids = model.generate(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            max_length=MAX_LENGTH_SUMMARY,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        batch_preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        predictions.extend(batch_preds)\n",
    "\n",
    "# Save predictions\n",
    "test_sample = test_df.iloc[:len(predictions)].copy()\n",
    "test_sample[\"predicted_summary\"] = predictions\n",
    "test_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ File has been saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>predicted_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Florida bus passenger was arrested for throw...</td>\n",
       "      <td>Joel Parker, 33, was riding the bus in St John...</td>\n",
       "      <td>Joel Parker, 33, was about to get off the Suns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aston Villa may be able to sign Cordoba strike...</td>\n",
       "      <td>Aston Villa have held talks over Cordoba strik...</td>\n",
       "      <td>Aston Villa could sign Cordoba striker Florin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles  \\\n",
       "0  A Florida bus passenger was arrested for throw...   \n",
       "1  Aston Villa may be able to sign Cordoba strike...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Joel Parker, 33, was riding the bus in St John...   \n",
       "1  Aston Villa have held talks over Cordoba strik...   \n",
       "\n",
       "                                   predicted_summary  \n",
       "0  Joel Parker, 33, was about to get off the Suns...  \n",
       "1  Aston Villa could sign Cordoba striker Florin ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores:\n",
      "ROUGE-1: 0.4039\n",
      "ROUGE-2: 0.1948\n",
      "ROUGE-L: 0.3863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore:\n",
      "Precision: 0.8880\n",
      "Recall:    0.8710\n",
      "F1:        0.8793\n",
      "METEOR Score (trung bình):\n",
      "METEOR: 0.2937\n"
     ]
    }
   ],
   "source": [
    "test_pred = pd.read_csv(output_path)\n",
    "display(test_pred[[\"articles\",\"summaries\", \"predicted_summary\"]].head(2))\n",
    "\n",
    "# Kiểm tra cột cần thiết\n",
    "if \"summaries\" in test_pred.columns and \"predicted_summary\" in test_pred.columns:\n",
    "    references = test_pred[\"summaries\"].fillna(\"<empty>\").astype(str).tolist()\n",
    "    predictions = test_pred[\"predicted_summary\"].fillna(\"<empty>\").astype(str).tolist()\n",
    "\n",
    "    # Lọc các cặp hợp lệ\n",
    "    valid_pairs = [\n",
    "        (pred, ref) for pred, ref in zip(predictions, references)\n",
    "        if pred.strip() and pred != \"<empty>\" and ref.strip()\n",
    "    ]\n",
    "    if not valid_pairs:\n",
    "        print(\"Không có cặp hợp lệ để tính điểm.\")\n",
    "    else:\n",
    "        filtered_preds, filtered_refs = zip(*valid_pairs)\n",
    "\n",
    "        # ROUGE\n",
    "        rouge = Rouge()\n",
    "        rouge_scores = rouge.get_scores(filtered_preds, filtered_refs, avg=True)\n",
    "        print(\"ROUGE scores:\")\n",
    "        print(f\"ROUGE-1: {rouge_scores['rouge-1']['f']:.4f}\")\n",
    "        print(f\"ROUGE-2: {rouge_scores['rouge-2']['f']:.4f}\")\n",
    "        print(f\"ROUGE-L: {rouge_scores['rouge-l']['f']:.4f}\")\n",
    "\n",
    "        # BERTScore\n",
    "        P, R, F1 = bert_score(filtered_preds, filtered_refs, lang=\"en\", verbose=False)\n",
    "        print(\"BERTScore:\")\n",
    "        print(f\"Precision: {P.mean().item():.4f}\")\n",
    "        print(f\"Recall:    {R.mean().item():.4f}\")\n",
    "        print(f\"F1:        {F1.mean().item():.4f}\")\n",
    "\n",
    "        # METEOR\n",
    "        print(\"METEOR Score (trung bình):\")\n",
    "        meteor_scores = [single_meteor_score(ref.split(), pred.split()) \n",
    "                        for pred, ref in zip(filtered_preds, filtered_refs)]\n",
    "        print(f\"METEOR: {sum(meteor_scores)/len(meteor_scores):.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Không tìm thấy đủ cột 'summaries' và 'predicted_summary' để tính điểm.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
