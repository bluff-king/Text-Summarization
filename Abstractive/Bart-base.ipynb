{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 13:37:18.584646: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-15 13:37:19.141830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744699039.347036    1467 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744699039.404705    1467 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744699039.888053    1467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744699039.888105    1467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744699039.888106    1467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744699039.888108    1467 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-15 13:37:19.946664: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from rouge import Rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 8\n",
    "FRAC_SAMPLE = 0.01\n",
    "MAX_LENGTH_ARTICLE = 512\n",
    "MIN_LENGTH_ARTICLE = 50\n",
    "MAX_LENGTH_SUMMARY = 128\n",
    "MIN_LENGTH_SUMMARY = 20\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_PLATEAU_COUNT = 7\n",
    "WEIGHT_DECAY = 1e-4\n",
    "USE_SCHEDULER = True\n",
    "NUM_CYCLES = 5\n",
    "\n",
    "\n",
    "model_dir = \"../Model\"\n",
    "datafilter = \"../dataft\"\n",
    "save_dir = \"fine_tuned_bart_cosine_4\"\n",
    "output_path = os.path.join(datafilter, \"test_pred_4.csv\")\n",
    "os.makedirs(datafilter, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19198 entries, 144417 to 201560\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  19198 non-null  object\n",
      " 1   articles            19198 non-null  object\n",
      " 2   summaries           19198 non-null  object\n",
      " 3   article_word_count  19198 non-null  int64 \n",
      " 4   summary_word_count  19198 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 899.9+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 994 entries, 8901 to 8365\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  994 non-null    object\n",
      " 1   articles            994 non-null    object\n",
      " 2   summaries           994 non-null    object\n",
      " 3   article_word_count  994 non-null    int64 \n",
      " 4   summary_word_count  994 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 46.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "validation_data = pd.read_csv(\"../dataset/validation.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "# add col\n",
    "train_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "validation_data.rename(columns={\"highlights\": \"summaries\",\"article\":\"articles\"}, inplace=True)\n",
    "test_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "\n",
    "train_data[\"article_word_count\"] = train_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "train_data[\"summary_word_count\"] = train_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "validation_data[\"article_word_count\"] = validation_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "validation_data[\"summary_word_count\"] = validation_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "test_data[\"article_word_count\"] = test_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "test_data[\"summary_word_count\"] = test_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# filter range\n",
    "train_data = train_data[\n",
    "    (train_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (train_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (train_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (train_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "validation_data = validation_data[\n",
    "    (validation_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (validation_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (validation_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (validation_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "test_data = test_data[\n",
    "    (test_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (test_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (test_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (test_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "train_sample = train_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "validation_sample = validation_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "test_sample = test_data.sample(frac=1, random_state=1)\n",
    "train_sample.info()\n",
    "print(\"\\n\")\n",
    "validation_sample.info()\n",
    "train_sample.to_csv(os.path.join(datafilter,\"train_sample.csv\"), index=False)\n",
    "test_sample.to_csv(os.path.join(datafilter,\"test_sample.csv\"), index=False)\n",
    "validation_sample.to_csv(os.path.join(datafilter,\"validation_sample.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19198 entries, 0 to 19197\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  19198 non-null  object\n",
      " 1   articles            19198 non-null  object\n",
      " 2   summaries           19198 non-null  object\n",
      " 3   article_word_count  19198 non-null  int64 \n",
      " 4   summary_word_count  19198 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 750.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sample = pd.read_csv(\"../dataft/train_sample.csv\")\n",
    "validation_sample = pd.read_csv(\"../dataft/validation_sample.csv\")\n",
    "test_sample = pd.read_csv(\"../dataft/test_sample.csv\")\n",
    "train_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_length=MAX_LENGTH_ARTICLE, max_output_length=MAX_LENGTH_SUMMARY):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        article = self.data.iloc[index][\"articles\"]\n",
    "        summary = self.data.iloc[index][\"summaries\"]\n",
    "        input_ids = self.tokenizer.encode(article, max_length=self.max_input_length, truncation=True, padding=\"max_length\")\n",
    "        output_ids = self.tokenizer.encode(summary, max_length=self.max_output_length, truncation=True, padding=\"max_length\")\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": [int(token_id != 0) for token_id in input_ids], \"decoder_input_ids\": output_ids[:-1], \"decoder_attention_mask\": [1] * (len(output_ids) - 1), \"labels\": output_ids[1:]}\n",
    "train_df = train_sample\n",
    "test_df = test_sample\n",
    "val_df = validation_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummarizationDataset(train_df, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    decoder_input_ids = [item[\"decoder_input_ids\"] for item in batch]\n",
    "    decoder_attention_mask = [item[\"decoder_attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    max_input_length = max(len(ids) for ids in input_ids)\n",
    "    max_output_length = max(len(ids) for ids in decoder_input_ids)\n",
    "    input_ids = [ids + [0] * (max_input_length - len(ids)) for ids in input_ids]\n",
    "    attention_mask = [mask + [0] * (max_input_length - len(mask)) for mask in attention_mask]\n",
    "    decoder_input_ids = [ids + [0] * (max_output_length - len(ids)) for ids in decoder_input_ids]\n",
    "    decoder_attention_mask = [mask + [0] * (max_output_length - len(mask)) for mask in decoder_attention_mask]\n",
    "    labels = [ids + [-100] * (max_output_length - len(ids)) for ids in labels]\n",
    "    return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "num_training_steps = (len(train_loader) * NUM_EPOCHS)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.2*num_training_steps),\n",
    "    num_training_steps=num_training_steps,\n",
    "    num_cycles=NUM_CYCLES \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader),len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvubkk67\u001b[0m (\u001b[33mvubkk67-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vuda/Text-Summarization/Abstractive/wandb/run-20250415_133753-8ed96a8j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/8ed96a8j' target=\"_blank\">bartbase-20250415-133752</a></strong> to <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/8ed96a8j' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/8ed96a8j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/8ed96a8j?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fed95f348f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Finetune-Summarization\",\n",
    "    name=f\"bartbase-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"model\": \"Bartbase_cosine_3\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"num_cycles\": NUM_CYCLES,\n",
    "        \"data_ratio\": FRAC_SAMPLE,\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e2628423184c35af3323e061d04cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4294ee2adf1e4e5699769c4d037aa95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuda/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:3353: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 1\n",
      "Epoch 01 | Train Loss: 6.6842 | Val Loss: 1.7433 | LR: 0.000002 | Time: 3545.45s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261f5be2c6fa4fda96427a46ede06823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa628b69a644da0888fc423e54f2202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 2\n",
      "Epoch 02 | Train Loss: 1.4059 | Val Loss: 1.0862 | LR: 0.000004 | Time: 3536.71s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90817dfa53234e149c30d982f0ae3e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d040f5a040047e09136823eab1d6d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 3\n",
      "Epoch 03 | Train Loss: 1.0780 | Val Loss: 0.9893 | LR: 0.000006 | Time: 3536.24s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1851a0f038d64f228759af99396b831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dbdd8df1b54533b37a735271aa71f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 4\n",
      "Epoch 04 | Train Loss: 0.9909 | Val Loss: 0.9517 | LR: 0.000008 | Time: 3535.62s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5dc7083fd74851828e70289f5da72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3f330cb5114402a74a2bd075773295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 5\n",
      "Epoch 05 | Train Loss: 0.9349 | Val Loss: 0.9183 | LR: 0.000010 | Time: 3541.56s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7402d5c13f64904ba6da0557c669d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e3ee0f738a46b598fd0c22b29600f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 6\n",
      "Epoch 06 | Train Loss: 0.8750 | Val Loss: 0.8912 | LR: 0.000008 | Time: 4649.90s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecad62272f34dc68b9a496ca507af53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e95dba92a04be1885c56f4385c2ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 7\n",
      "Epoch 07 | Train Loss: 0.8250 | Val Loss: 0.8646 | LR: 0.000003 | Time: 6934.88s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b4f6bdf7484936b98b0fe71b562f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e63f9047d4df1902077a1a3ba573e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 8\n",
      "Epoch 08 | Train Loss: 0.7915 | Val Loss: 0.8617 | LR: 0.000000 | Time: 6693.46s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2db70ec54543d0af04270e774cac2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4223f5f62f494980848d7bba2e615395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 0.7839 | Val Loss: 0.8642 | LR: 0.000001 | Time: 6689.07s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73737b873a624b23b89fa0f0743237e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36006d8a20ac4cb3857c49057f5b911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 10\n",
      "Epoch 10 | Train Loss: 0.7824 | Val Loss: 0.8483 | LR: 0.000006 | Time: 6691.95s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c1e6ff0d254762a4d8afe8502f6922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0128cb5063a149dba33e6fe5b9fae4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 11\n",
      "Epoch 11 | Train Loss: 0.7708 | Val Loss: 0.8478 | LR: 0.000010 | Time: 6680.27s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b6ea4691464a4d8504c86cb7479068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e6c3c22d0d4b528b47eae239214ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 12\n",
      "Epoch 12 | Train Loss: 0.7463 | Val Loss: 0.8467 | LR: 0.000009 | Time: 6680.45s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a934e3dbb3422dbfe6a29d23b77f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62906c443edc45d4bb338abb06c1d592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart_cosine_3` at epoch 13\n",
      "Epoch 13 | Train Loss: 0.7134 | Val Loss: 0.8409 | LR: 0.000005 | Time: 6687.05s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f16a264b904795b3495a2b5c96993b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d48a3c234f040d6847e7ecff13e654e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6858 | Val Loss: 0.8419 | LR: 0.000001 | Time: 6680.70s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48ca9e2b8bf48adac0550b082eba904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb59ec8170c4855b5f3f3730752db30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6724 | Val Loss: 0.8431 | LR: 0.000000 | Time: 6689.28s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943aad5816f647ed91029ce364cb438e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b64f9ab34a4144947c5a9a217d9e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.6726 | Val Loss: 0.8419 | LR: 0.000004 | Time: 6681.27s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374282b249c5422d85f7a12f38e48dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b77c6cdb34b49dda1692ab41fd0cff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6742 | Val Loss: 0.8486 | LR: 0.000008 | Time: 6680.23s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbdc9d0d84b4f70a37a298d7fbb9286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8680ba0ebeea4066bcd64871863afc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6655 | Val Loss: 0.8519 | LR: 0.000010 | Time: 6681.74s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe22cb69b614d56a2fe77de2977479f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20ba7206ecf4154b2cff167a04fa42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.6440 | Val Loss: 0.8519 | LR: 0.000007 | Time: 6674.54s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f175a9f535e4603b9153e005529e336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2e392327414caea292ab07372d984d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6165 | Val Loss: 0.8522 | LR: 0.000003 | Time: 6665.81s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf187704a29d4728a87c53cdc738e661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e414e399813744409460f646f07a5792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5965 | Val Loss: 0.8545 | LR: 0.000000 | Time: 6869.01s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fdff387d4c459596989b8be054194a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5d525022f146ef908896dd3f66c95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5931 | Val Loss: 0.8561 | LR: 0.000002 | Time: 6947.32s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac9c21893784ff496864b93abb6f8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1a93e55268429eaff076bfc005fd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5973 | Val Loss: 0.8610 | LR: 0.000007 | Time: 6680.22s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c94a983f8d640f2b8e404498e23cb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0e377eda1d400eb951cc43e65d48ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5963 | Val Loss: 0.8610 | LR: 0.000010 | Time: 6680.61s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40c517061184bc6be18463e3e04f73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save best model\n",
    "best_val_loss = float(\"inf\")\n",
    "# W&B setup\n",
    "wandb.watch(model)\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}  # Thêm dòng này\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    # W&B log\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"lr\": current_lr,\n",
    "        \"best_val_loss\": best_val_loss\n",
    "    })\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model.save_pretrained(save_dir)\n",
    "        tokenizer.save_pretrained(save_dir)\n",
    "        print(f\"Saved best model to `{save_dir}` at epoch {epoch+1}\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"LR: {current_lr:.6f} | \"\n",
    "        f\"Time: {time.time() - start_time:.2f}s\"\n",
    "    )\n",
    "\n",
    "# W&B end\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = PegasusTokenizer.from_pretrained(save_dir)\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(save_dir).to(device)\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(save_dir)\n",
    "model = BartForConditionalGeneration.from_pretrained(save_dir).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = SummarizationDataset(test_df, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,collate_fn=collate_fn)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220dfd00ca14475ea14743b0a2caa7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating summaries:   0%|          | 0/528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File has been saved at: ../dataft/test_pred_3.csv\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(test_loader, desc=\"Generating summaries\")):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        output_ids = model.generate(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            max_length=MAX_LENGTH_SUMMARY,\n",
    "            decoder_start_token_id=tokenizer.pad_token_id,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        batch_preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        predictions.extend(batch_preds)\n",
    "test_sample = test_sample.iloc[:len(predictions)].copy()\n",
    "test_sample[\"predicted_summary\"] = predictions\n",
    "test_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ File has been saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>predicted_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Florida bus passenger was arrested for throw...</td>\n",
       "      <td>Joel Parker, 33, was riding the bus in St John...</td>\n",
       "      <td>Joel Parker, 33, was about to get off the Sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aston Villa may be able to sign Cordoba strike...</td>\n",
       "      <td>Aston Villa have held talks over Cordoba strik...</td>\n",
       "      <td>ston Villa may be able to sign Cordoba striker...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles  \\\n",
       "0  A Florida bus passenger was arrested for throw...   \n",
       "1  Aston Villa may be able to sign Cordoba strike...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Joel Parker, 33, was riding the bus in St John...   \n",
       "1  Aston Villa have held talks over Cordoba strik...   \n",
       "\n",
       "                                   predicted_summary  \n",
       "0   Joel Parker, 33, was about to get off the Sun...  \n",
       "1  ston Villa may be able to sign Cordoba striker...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_pred[[\"articles\",\"summaries\", \"predicted_summary\"]].head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores:\n",
      "ROUGE-1: 0.3807\n",
      "ROUGE-2: 0.1660\n",
      "ROUGE-L: 0.3589\n"
     ]
    }
   ],
   "source": [
    "# Tính điểm ROUGE\n",
    "if \"summaries\" in test_pred.columns:\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predictions, test_sample[\"summaries\"].tolist(), avg=True)\n",
    "\n",
    "    print(\"ROUGE scores:\")\n",
    "    print(f\"ROUGE-1: {scores['rouge-1']['f']:.4f}\")\n",
    "    print(f\"ROUGE-2: {scores['rouge-2']['f']:.4f}\")\n",
    "    print(f\"ROUGE-L: {scores['rouge-l']['f']:.4f}\")\n",
    "else:\n",
    "    print(\"⚠️ Không tìm thấy cột 'summaries' để tính ROUGE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
