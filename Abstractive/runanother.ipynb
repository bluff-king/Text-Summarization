{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "FRAC_SAMPLE = 0.03\n",
    "MAX_LENGTH_ARTICLE = 512\n",
    "MIN_LENGTH_ARTICLE = 50\n",
    "MAX_LENGTH_SUMMARY = 128\n",
    "MIN_LENGTH_SUMMARY = 20\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_CYCLES = 3\n",
    "MAX_PLATEAU_COUNT = 5\n",
    "WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_warmup_decay(step, warmup_steps, total_steps):\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / (warmup_steps + 1)\n",
    "    else:\n",
    "        return max(1e-7, (total_steps - step) / (total_steps - warmup_steps))\n",
    "\n",
    "\n",
    "def warmup_cosine_with_restarts(step, warmup_steps, total_steps, num_cycles=1):\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / (warmup_steps + 1)\n",
    "    else:\n",
    "        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "        cycle_progress = progress * num_cycles % 1\n",
    "        return max(1e-7, 0.5 * (1 + math.cos(math.pi * cycle_progress)))\n",
    "\n",
    "\n",
    "\n",
    "def get_scheduler(\n",
    "    optimizer, total_steps, warmup_steps, num_cycles=None, types='warmup_cosine_with_restarts'\n",
    "):\n",
    "    if types == 'warmup_cosine_with_restarts':\n",
    "        assert num_cycles != None, 'must specify num_cycles when types=\"warmup_cosine_with_restarts\"'\n",
    "        return torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda step: warmup_cosine_with_restarts(\n",
    "                step, warmup_steps, total_steps, num_cycles=num_cycles)\n",
    "        )\n",
    "    elif types == 'linear_warmup_decay':\n",
    "        return torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda step: linear_warmup_decay(step, warmup_steps, total_steps)\n",
    "        )\n",
    "    else:\n",
    "        raise Exception('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../Model\"\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "validation_data = pd.read_csv(\"../dataset/validation.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "train_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "validation_data.rename(columns={\"highlights\": \"summaries\",\"article\":\"articles\"}, inplace=True)\n",
    "test_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"article_word_count\"] = train_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "train_data[\"summary_word_count\"] = train_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "validation_data[\"article_word_count\"] = validation_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "validation_data[\"summary_word_count\"] = validation_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "test_data[\"article_word_count\"] = test_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "test_data[\"summary_word_count\"] = test_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc train_data\n",
    "train_data = train_data[\n",
    "    (train_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (train_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (train_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (train_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "# Lọc validation_data\n",
    "validation_data = validation_data[\n",
    "    (validation_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (validation_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (validation_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (validation_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "# Lọc test_data\n",
    "test_data = test_data[\n",
    "    (test_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (test_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (test_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (test_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2880 entries, 144417 to 2426\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  2880 non-null   object\n",
      " 1   articles            2880 non-null   object\n",
      " 2   summaries           2880 non-null   object\n",
      " 3   article_word_count  2880 non-null   int64 \n",
      " 4   summary_word_count  2880 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 135.0+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 149 entries, 8901 to 5720\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  149 non-null    object\n",
      " 1   articles            149 non-null    object\n",
      " 2   summaries           149 non-null    object\n",
      " 3   article_word_count  149 non-null    int64 \n",
      " 4   summary_word_count  149 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 7.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sample = train_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "validation_sample = validation_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "test_sample = test_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "train_sample.info()\n",
    "print(\"\\n\")\n",
    "validation_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25004\n",
      "Embedding shape: (25004, 104)\n",
      "<PAD> embedding last 4 dims: [1.0, 0.0, 0.0, 0.0]\n",
      "<SOS> embedding last 4 dims: [0.0, 1.0, 0.0, 0.0]\n",
      "Word 'the' embedding last 4 dims: [0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = \"../Embedding/glove-wiki-gigaword-100.txt\"\n",
    "vocab, embeddings = [], []\n",
    "with open(EMBEDDING_FILE, 'rt', encoding='utf-8') as ef:\n",
    "    full_content = ef.read().strip().split('\\n')\n",
    "for i in range(len(full_content)):\n",
    "    i_word = full_content[i].split(' ')[0]\n",
    "    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "    i_embeddings.extend([0.0, 0.0, 0.0, 0.0])\n",
    "    vocab.append(i_word)\n",
    "    embeddings.append(i_embeddings)\n",
    "\n",
    "embs_npa = np.array(embeddings)\n",
    "\n",
    "unk_embedding = np.mean(embs_npa, axis=0).tolist()\n",
    "\n",
    "dim = embs_npa.shape[1]\n",
    "sos_embedding = [0.0] * dim\n",
    "sos_embedding[-3] = 1.0\n",
    "eos_embedding = [0.0] * dim\n",
    "eos_embedding[-2] = 1.0\n",
    "pad_embedding = [0.0] * dim\n",
    "pad_embedding[-4] = 1.0\n",
    "# unk_embedding = [0.0] * dim\n",
    "# unk_embedding[-1] = 1.0\n",
    "\n",
    "# Update vocab and embeddings\n",
    "vocab = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"] + vocab\n",
    "embeddings = [pad_embedding, sos_embedding,\n",
    "              eos_embedding, unk_embedding] + embeddings\n",
    "\n",
    "vocab_npa = np.array(vocab)\n",
    "embs_npa = np.array(embeddings)\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().strip().split()\n",
    "\n",
    "\n",
    "stoi_dict = {word: idx for idx, word in enumerate(vocab_npa)}\n",
    "_unk_idx = stoi_dict[\"<UNK>\"]\n",
    "itos = {idx: word for word, idx in stoi_dict.items()}\n",
    "\n",
    "def stoi(string, stoi_dict=stoi_dict):\n",
    "    return stoi_dict.get(string, _unk_idx)\n",
    "\n",
    "\n",
    "def numericalize(text):\n",
    "    tokenized_text = tokenize(text)\n",
    "    return [\n",
    "        stoi(token)\n",
    "        for token in tokenized_text\n",
    "    ]\n",
    "\n",
    "print(embs_npa.shape[0])\n",
    "embedding_layer = torch.nn.Embedding.from_pretrained(torch.FloatTensor(embeddings),\n",
    "                                                     freeze=False,\n",
    "                                                     padding_idx=stoi(\"<PAD>\"))\n",
    "embedding_layer.to(device)\n",
    "vocab_size = len(vocab_npa)\n",
    "print(\"Embedding shape:\", np.array(embeddings).shape) \n",
    "print(\"<PAD> embedding last 4 dims:\", embeddings[stoi(\"<PAD>\")][-4:])\n",
    "print(\"<SOS> embedding last 4 dims:\", embeddings[stoi(\"<SOS>\")][-4:])\n",
    "print(\"Word 'the' embedding last 4 dims:\", embeddings[stoi(\"the\")][-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, articles, summaries, stoi, max_len_article=MAX_LENGTH_ARTICLE, max_len_summary=MAX_LENGTH_SUMMARY):\n",
    "        self.articles = articles  # List of articles\n",
    "        self.summaries = summaries  # List of summaries\n",
    "        self.stoi = stoi  # String-to-index dictionary\n",
    "        self.pad_idx = stoi(\"<PAD>\")\n",
    "        self.sos_idx = stoi(\"<SOS>\")\n",
    "        self.eos_idx = stoi(\"<EOS>\")\n",
    "        \n",
    "        # Determine max lengths if not provided\n",
    "        self.max_len_article = max_len_article or max(len(a.split()) for a in articles) + 2\n",
    "        self.max_len_summary = max_len_summary or max(len(s.split()) for s in summaries) + 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def process_text(text, max_len):\n",
    "            tokens = [self.sos_idx] + [self.stoi(w) for w in text.split()] + [self.eos_idx]  # Tokenize and add SOS/EOS\n",
    "            tokens = tokens[:max_len] + [self.pad_idx] * (max_len - len(tokens))  # Pad to max length\n",
    "            return torch.tensor(tokens), len(tokens)\n",
    "\n",
    "        article_tokens, article_len = process_text(self.articles[idx], self.max_len_article)\n",
    "        summary_tokens, summary_len = process_text(self.summaries[idx], self.max_len_summary)\n",
    "        \n",
    "        return {\n",
    "            'article': article_tokens,  # Encoded article\n",
    "            'article_len': torch.tensor(article_len),\n",
    "            'summary': summary_tokens,  # Encoded summary\n",
    "            'summary_len': torch.tensor(summary_len)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Batch is list os the dict {'article': ..., 'summary': ...}\n",
    "    return {\n",
    "        'article': torch.stack([item['article'] for item in batch]),\n",
    "        'article_len': torch.tensor([item['article_len'] for item in batch]),\n",
    "        'summary': torch.stack([item['summary'] for item in batch]),\n",
    "        'summary_len': torch.tensor([item['summary_len'] for item in batch])\n",
    "    }\n",
    "\n",
    "# DataLoader setup\n",
    "# torch.set_printoptions(profile=\"full\")\n",
    "torch.set_printoptions(profile=\"default\")\n",
    "train_dataset = Seq2SeqDataset(train_sample['articles'].tolist(), train_sample['summaries'].tolist(), stoi)\n",
    "# print(train_dataset[268][\"article\"])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset= Seq2SeqDataset(validation_sample['articles'].tolist(), validation_sample['summaries'].tolist(), stoi)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding.embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x, seq_lens):\n",
    "        x = self.dropout(self.embedding(x))\n",
    "        packed = pack_padded_sequence(\n",
    "            input=x,\n",
    "            lengths=seq_lens.cpu(),\n",
    "            batch_first=True, \n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.lstm(packed)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1, bias=False))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs, mask=None):\n",
    "        # decoder_hidden: [batch, hidden]\n",
    "        # encoder_outputs: [batch, seq_len, hidden]\n",
    "        \n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1)  # [batch, 1, hidden]\n",
    "        \n",
    "        # Repeat decoder hidden state across sequence length\n",
    "        decoder_hidden = decoder_hidden.expand(-1, encoder_outputs.size(1), -1)\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        energy_input = torch.cat([encoder_outputs, decoder_hidden], dim=2)\n",
    "        scores = self.energy(self.dropout(energy_input)).squeeze(2)  # [batch, seq_len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e10)\n",
    "            \n",
    "        attn_weights = F.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "        \n",
    "        return context, attn_weights\n",
    "\n",
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.attention = SimpleAttention(hidden_dim)\n",
    "        self.lstm = nn.LSTMCell(\n",
    "            input_size=self.embedding.embedding_dim + hidden_dim,\n",
    "            hidden_size=hidden_dim\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.xavier_uniform_(self.fc_out.weight)\n",
    "        if self.fc_out.bias is not None:\n",
    "            self.fc_out.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x, prev_hidden, prev_cell, encoder_outputs, mask=None):\n",
    "        x = self.dropout(self.embedding(x))  # [batch] -> [batch, emb_dim]\n",
    "        \n",
    "        if prev_hidden.dim() == 3:\n",
    "            prev_hidden = prev_hidden[-1]  # Take last layer if multi-layer\n",
    "        \n",
    "        context, attn_weights = self.attention(prev_hidden, encoder_outputs, mask)\n",
    "        \n",
    "        # LSTM update\n",
    "        lstm_input = torch.cat([x, context], dim=1)\n",
    "        hidden, cell = self.lstm(lstm_input, (prev_hidden, prev_cell))\n",
    "        \n",
    "        # Output prediction\n",
    "        output = self.fc_out(torch.cat([hidden, context], dim=1))\n",
    "        return output, hidden, cell, attn_weights\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.encoder = SimpleEncoder(embedding_layer, hidden_dim)\n",
    "        self.decoder = SimpleDecoder(embedding_layer, hidden_dim, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.start_id = 2  # <SOS> token id\n",
    "        self.end_id = 3    # <EOS> token id\n",
    "        \n",
    "        # Projection layers for encoder to decoder states\n",
    "        self.hidden_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.cell_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Initialize projections\n",
    "        for proj in [self.hidden_proj, self.cell_proj]:\n",
    "            nn.init.xavier_uniform_(proj.weight)\n",
    "            proj.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, src, src_lens, trg=None, max_len=None, teacher_forcing_ratio=0.5):\n",
    "        # Encoder forward\n",
    "        enc_outputs, (hidden, cell) = self.encoder(src, src_lens)\n",
    "        \n",
    "        # Project encoder states to decoder space\n",
    "        hidden = self.hidden_proj(hidden.squeeze(0))\n",
    "        cell = self.cell_proj(cell.squeeze(0))\n",
    "        \n",
    "        # Determine max length\n",
    "        batch_size = src.size(0)\n",
    "        if trg is not None:\n",
    "            max_len = trg.size(1)\n",
    "        else:\n",
    "            max_len = max_len if max_len is not None else 100\n",
    "            \n",
    "        # Initialize outputs tensor\n",
    "        outputs = torch.zeros(batch_size, max_len, self.vocab_size).to(src.device)\n",
    "        \n",
    "        # First input is SOS token\n",
    "        x = torch.full((batch_size,), self.start_id, dtype=torch.long, device=src.device)\n",
    "        \n",
    "        # Create mask from padding\n",
    "        mask = (src != 0)  # Assuming 0 is pad_idx\n",
    "        \n",
    "        # Decoding loop\n",
    "        for t in range(max_len):\n",
    "            output, hidden, cell, _ = self.decoder(\n",
    "                x=x,\n",
    "                prev_hidden=hidden,\n",
    "                prev_cell=cell,\n",
    "                encoder_outputs=enc_outputs,\n",
    "                mask=mask\n",
    "            )\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            # Decide next input\n",
    "            if trg is not None and random.random() < teacher_forcing_ratio:\n",
    "                x = trg[:, t]\n",
    "            else:\n",
    "                x = output.argmax(1)\n",
    "                \n",
    "            # Early stopping if all sequences predicted EOS\n",
    "            if (x == self.end_id).all() and trg is None:\n",
    "                outputs = outputs[:, :t+1]  # Chỉ trim khi inference\n",
    "                break\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvubkk67\u001b[0m (\u001b[33mvubkk67-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vuda/Text-Summarization/Abstractive/wandb/run-20250406_143843-ea3kjxoe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/ea3kjxoe' target=\"_blank\">seq2seq-20250406-143842</a></strong> to <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/ea3kjxoe' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/ea3kjxoe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/ea3kjxoe?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0249962ab0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Seq2Seq-Summarization\",\n",
    "    name=f\"seq2seq-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"model\": \"Seq2Seq-LSTM\",\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"teacher_forcing_ratio\": 1.0,\n",
    "        \"vocab_size\": len(vocab)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a61164c900a432f9649659a16b7590e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc55a9da4e34ec7b1d69ea9d492ad3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 6.6745 | Val Loss: 5.4151 | LR: 0.001673 | Time: 160.84s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dba054697a423db39433d2f37e4836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecab596ac8346e68f6cc46f4d7b1ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 5.4335 | Val Loss: 5.3730 | LR: 0.003336 | Time: 162.59s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7438a2242074d6cb902fbf20b8f9b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c76780424394a20ba0e2f696628a6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 5.3354 | Val Loss: 5.4149 | LR: 0.005000 | Time: 162.04s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf32feb775514646be3a3b0c24cb441f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594f3b0128d847ad8c5d743bbf75e952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 5.2417 | Val Loss: 5.3806 | LR: 0.004849 | Time: 160.41s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6e3eeec2754873b8ff52377be0afe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb102f9f07b4ae7adfec175e1b60a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 5.1803 | Val Loss: 5.3223 | LR: 0.004415 | Time: 160.01s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb563910edc545f1a05940625cf93dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1356bc455e84a58a44ed83ea57967e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 5.1361 | Val Loss: 5.2705 | LR: 0.003750 | Time: 159.68s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ac7fbb2f1b491b944c345c4cf5fbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edc373887fa4885b86373ddc1504148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 5.0911 | Val Loss: 5.2885 | LR: 0.002934 | Time: 159.59s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a68d0a2ab2849a39af23be46c6a6079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1291d049b548d58bd641a74c5c58c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 5.0549 | Val Loss: 5.2958 | LR: 0.002066 | Time: 159.91s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1f9a663c244149ac82f5772b31b46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce06b3ceecb462bbe85c7571944d2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 5.0203 | Val Loss: 5.2875 | LR: 0.001250 | Time: 159.32s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7087459e70d049f2a515195e58775430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a127135ce64d17a907655546c22ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 4.9838 | Val Loss: 5.2464 | LR: 0.000585 | Time: 159.78s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b51f27cf504ddb92adf8276ab156ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dde9250e056429da09d7a30961f4aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 4.9438 | Val Loss: 5.2137 | LR: 0.000151 | Time: 159.51s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b35d9761b04822823aa67a35ae4813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b9313a9b2941aca6b709dbaa0a62fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 4.9098 | Val Loss: 5.2571 | LR: 0.005000 | Time: 162.13s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09df834c20684201b7c3b17a0b0acd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8c17b4846d466a865e2d2e95650b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 5.0851 | Val Loss: 5.3083 | LR: 0.004849 | Time: 159.25s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e586cc02900946b2bec05e265857e5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7ffe5d142948a09ff1e773562d58fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 5.0386 | Val Loss: 5.2852 | LR: 0.004415 | Time: 158.96s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d3f0851af4470782f3057fd6992274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1946229754a64fc78b1a948438275e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 5.0008 | Val Loss: 5.2401 | LR: 0.003750 | Time: 158.71s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e5b768a8f140019e186aaeecd85f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c69bfc08414e1ab0778070457bc4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 4.9586 | Val Loss: 5.2612 | LR: 0.002934 | Time: 158.88s\n",
      "Validation loss hasn't improved for 5 epochs. Stopping training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8567fb60d84bfd9816664e74e2979e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.037 MB of 0.037 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td> █▇▇▇▅▃▃▃▃▂▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▃▆██▇▆▅▄▃▂▁██▇▆▅</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▂▁▁▁▁▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▇█▇▅▃▄▄▄▂▁▃▄▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>5.21369</td></tr><tr><td>epoch</td><td>16</td></tr><tr><td>lr</td><td>0.00293</td></tr><tr><td>train_loss</td><td>4.95862</td></tr><tr><td>val_loss</td><td>5.26122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seq2seq-20250406-143842</strong> at: <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/ea3kjxoe' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/ea3kjxoe</a><br/> View project at: <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250406_143843-ea3kjxoe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        src = batch['article'].to(device)\n",
    "        src_lens = batch['article_len'].to(device)\n",
    "        trg = batch['summary'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with teacher forcing\n",
    "        outputs = model(src, src_lens, trg=trg, teacher_forcing_ratio=0.5)\n",
    "        \n",
    "        # Calculate loss (ignore padding)\n",
    "        min_len = min(outputs.size(1), trg.size(1))\n",
    "        loss = criterion(\n",
    "            outputs[:, 1:min_len].reshape(-1, outputs.size(-1)),\n",
    "            trg[:, 1:min_len].reshape(-1)\n",
    ")\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            src = batch['article'].to(device)\n",
    "            src_lens = batch['article_len'].to(device)\n",
    "            trg = batch['summary'].to(device)\n",
    "            \n",
    "            outputs = model(src, src_lens, trg=trg, teacher_forcing_ratio=0)\n",
    "            loss = criterion(\n",
    "                outputs[:, 1:].reshape(-1, outputs.size(-1)),\n",
    "                trg[:, 1:].reshape(-1)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "# Save best Model\n",
    "best_model_path = os.path.join(model_dir, \"best_model_128.pth\")\n",
    "embedding_layer = torch.nn.Embedding.from_pretrained(\n",
    "    torch.FloatTensor(embeddings),\n",
    "    freeze=False,\n",
    "    padding_idx=stoi(\"<PAD>\")\n",
    ").to(device)\n",
    "\n",
    "# 3. Khởi tạo model\n",
    "model = Seq2SeqModel(\n",
    "    embedding_layer=embedding_layer,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "\n",
    "# 4. Train loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi(\"<PAD>\"))\n",
    "best_val_loss = float('inf')\n",
    "# Initialize learning rate scheduler\n",
    "total_steps = NUM_EPOCHS * len(train_loader)\n",
    "warmup_steps = int(0.1 * total_steps)  # 10% of total steps for warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    optimizer, \n",
    "    total_steps=total_steps,\n",
    "    warmup_steps=warmup_steps,\n",
    "    num_cycles=NUM_CYCLES\n",
    ")\n",
    "plateau_count = 0\n",
    "wandb.watch(model)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion, device,lr_scheduler)\n",
    "    \n",
    "    # Eval\n",
    "    val_loss = evaluate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    current_lr = lr_scheduler.get_last_lr()[0] if lr_scheduler else LEARNING_RATE\n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch+1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"best_val_loss\": best_val_loss, \n",
    "        \"lr\": current_lr\n",
    "    })\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        plateau_count = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler_state_dict': lr_scheduler.state_dict() if lr_scheduler else None,\n",
    "        }, best_model_path)\n",
    "    else:\n",
    "        plateau_count += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"LR: {current_lr:.6f} | \"\n",
    "          f\"Time: {time.time()-start_time:.2f}s\")\n",
    "    \n",
    "    # Early stopping if validation loss doesn't improve\n",
    "    if plateau_count >= MAX_PLATEAU_COUNT:\n",
    "        print(f\"Validation loss hasn't improved for {MAX_PLATEAU_COUNT} epochs. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# Kết thúc W&B\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_indices(indices, itos):\n",
    "    tokens = []\n",
    "    for idx in indices:\n",
    "        token = itos.get(idx.item(), \"<UNK>\")\n",
    "        if token == \"<EOS>\":\n",
    "            break\n",
    "        if token not in {\"<SOS>\", \"<PAD>\"}:\n",
    "            tokens.append(token)\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_359882/3193279668.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_model_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqModel(\n",
       "  (encoder): SimpleEncoder(\n",
       "    (embedding): Embedding(25004, 104, padding_idx=0)\n",
       "    (lstm): LSTM(104, 128, batch_first=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): SimpleDecoder(\n",
       "    (embedding): Embedding(25004, 104, padding_idx=0)\n",
       "    (attention): SimpleAttention(\n",
       "      (energy): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (1): Tanh()\n",
       "        (2): Linear(in_features=128, out_features=1, bias=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lstm): LSTMCell(232, 128)\n",
       "    (fc_out): Linear(in_features=256, out_features=25004, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (hidden_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (cell_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load lại model\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📰 Input Article:\n",
      " A Florida bus passenger was arrested for throwing a Snickers bar at the driver's head after threatening him and being disruptive during the ride, according to police. Joel Parker, 33, was about to get off the Sunshine Bus in St Johns County on Wednesday when he asked the driver if he would like a Snickers bar. When the driver declined the offering, Parker threw the candy bar at his head instead, police said. The driver was not injured but called the police and Parker was arrested for battery, according to WFTV. Parker posted $250 bond and was issued a trespass warning. He is also never allowed to use the bus again. Joel Parker, 33, was arrested for throwing a Snickers bar at a bus driver's head after threatening and disrupting him during the ride through St Johns County, Florida, according to police .\n",
      "\n",
      "✅ True Summary:\n",
      " Joel Parker, 33, was riding the bus in St Johns County, Florida .\n",
      "Police said he threatened the driver and was disruptive during the ride .\n",
      "As he got off the bus he offered the candy bar to the driver, who declined .\n",
      "He was arrested for battery and is never allowed to ride the bus again .\n",
      "\n",
      "🤖 Predicted Summary:\n",
      " <UNK>\n"
     ]
    }
   ],
   "source": [
    "# Lấy một sample\n",
    "test_article = test_sample.iloc[0]['articles']\n",
    "true_summary = test_sample.iloc[0]['summaries']\n",
    "\n",
    "# Tiền xử lý như trong Dataset\n",
    "tokens = [stoi(\"<SOS>\")] + [stoi(w) for w in test_article.split()] + [stoi(\"<EOS>\")]\n",
    "tokens = tokens[:MAX_LENGTH_ARTICLE] + [stoi(\"<PAD>\")] * (MAX_LENGTH_ARTICLE - len(tokens))\n",
    "src_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "src_len = torch.tensor([len(tokens)]).to(device)\n",
    "\n",
    "# Dự đoán\n",
    "with torch.no_grad():\n",
    "    output = model(src_tensor, src_len, trg=None, teacher_forcing_ratio=0.0)\n",
    "\n",
    "# Lấy chuỗi dự đoán\n",
    "pred_indices = output.argmax(dim=-1).squeeze(0)\n",
    "pred_summary = decode_indices(pred_indices, itos)\n",
    "\n",
    "# In kết quả\n",
    "print(\"\\n📰 Input Article:\\n\", test_article)\n",
    "print(\"\\n✅ True Summary:\\n\", true_summary)\n",
    "print(\"\\n🤖 Predicted Summary:\\n\", pred_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
