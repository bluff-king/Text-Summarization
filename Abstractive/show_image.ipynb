{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2005343661.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://www.ijcaonline.org/archives/volume185/number15/patil-2023-ijca-922837.pdf\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/text-summarization-using-deep-neural-networks-e7ee7521d804/  \n",
    "https://saadsohail5104.medium.com/understanding-padding-in-nlp-types-and-when-to-use-them-bacae6cae401\n",
    "https://github.com/rohithreddy024/Text-Summarizer-Pytorch/blob/master/data_util/data.py\n",
    "https://www.ijcaonline.org/archives/volume185/number15/patil-2023-ijca-922837.pdf\n",
    "https://www.kaggle.com/code/getanmolgupta01/text-summarization-lstm-encoder-decoder\n",
    "https://github.com/rohithreddy024/Text-Summarizer-Pytorch/blob/master/model.py\n",
    "https://arxiv.org/abs/1508.04025\n",
    "https://www.freecodecamp.org/news/what-is-rouge-and-how-it-works-for-evaluation-of-summaries-e059fb8ac840/#:~:text=ROUGE%20stands%20for%20Recall%2DOriented,as%20well%20as%20machine%20translations.&text=If%20we%20consider%20just%20the,and%20reference%20summary%20is%206.\n",
    "https://www.kaggle.com/code/quadeer15sh/introduction-to-language-modelling-using-rnns\n",
    "https://www.kaggle.com/code/divyanshvishwkarma/seq2seq-model-with-attention-teacher-forcing-tf # nguồn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi-document summarization: Nghiên cứu từ PMC (2020) so sánh BART, T5, và PEGASUS trong bối cảnh zero-shot và few-shot cho tóm tắt đa tài liệu. Họ nhận thấy rằng với dữ liệu fine-tuning hạn chế (10 mẫu), không có sự khác biệt đáng kể về chất lượng tóm tắt giữa các mô hình, cho thấy ensemble có thể không mang lại lợi ích lớn trong trường hợp này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight decay chỉ áp dụng cho weight, exclucde bias & LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The tokenizer is designed specifically for the Pegasus model, using a sentencepiece-based subword tokenization (BPE-like) that aligns well with the model’s input expectations. This ensures that tokenized inputs are formatted correctly for the Pegasus encoder-decoder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chúng ta sẽ sử dụng phương pháp Weighted Voting Ensemble kết hợp với Post-processing. Phương pháp này tận dụng điểm mạnh của từng mô hình (BART mạnh về ngữ pháp và tính mạch lạc, T5 tốt về độ ngắn gọn, Pegasus tốt về việc nắm bắt ý chính) bằng cách kết hợp các tóm tắt được tạo ra từ mỗi mô hình dựa trên trọng số (weight) được xác định từ hiệu suất trên tập validation (ví dụ: ROUGE hoặc BERTScore). Sau đó, một bước hậu xử lý sẽ được áp dụng để đảm bảo tóm tắt cuối cùng mạch lạc và không trùng lặp."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
