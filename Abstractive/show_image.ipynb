{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2005343661.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://www.ijcaonline.org/archives/volume185/number15/patil-2023-ijca-922837.pdf\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/text-summarization-using-deep-neural-networks-e7ee7521d804/  \n",
    "https://saadsohail5104.medium.com/understanding-padding-in-nlp-types-and-when-to-use-them-bacae6cae401\n",
    "https://github.com/rohithreddy024/Text-Summarizer-Pytorch/blob/master/data_util/data.py\n",
    "https://www.ijcaonline.org/archives/volume185/number15/patil-2023-ijca-922837.pdf\n",
    "https://www.kaggle.com/code/getanmolgupta01/text-summarization-lstm-encoder-decoder\n",
    "https://github.com/rohithreddy024/Text-Summarizer-Pytorch/blob/master/model.py\n",
    "https://arxiv.org/abs/1508.04025\n",
    "https://www.freecodecamp.org/news/what-is-rouge-and-how-it-works-for-evaluation-of-summaries-e059fb8ac840/#:~:text=ROUGE%20stands%20for%20Recall%2DOriented,as%20well%20as%20machine%20translations.&text=If%20we%20consider%20just%20the,and%20reference%20summary%20is%206.\n",
    "https://www.kaggle.com/code/quadeer15sh/introduction-to-language-modelling-using-rnns\n",
    "https://www.kaggle.com/code/divyanshvishwkarma/seq2seq-model-with-attention-teacher-forcing-tf # nguồn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim=HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer  # from_pretrained\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding.embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=False  # Unidirectional\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, seq_lens):\n",
    "        x = self.embedding(x)\n",
    "    \n",
    "        packed = pack_padded_sequence(input=x,lengths=seq_lens.cpu(),batch_first=True, enforce_sorted=False  \n",
    "        )\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(packed)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        return output, (hidden, cell)  # hidden shape: [1, batch_size, hidden_dim]\n",
    "    \n",
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),  # Nhận input là [encoder_output + decoder_hidden]\n",
    "            nn.Tanh(),                      \n",
    "            nn.Linear(hidden_dim, 1, bias=False)    #  Trả về 1 chiều attention scores\n",
    "        )\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_outputs, mask=None):\n",
    "        #########  decoder_hidden = decoder_hidden.unsqueeze(1).expand_as(encoder_outputs)  # [batch_size, seq_len, hidden_dim]\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1)  # [batch_size, 1, hidden_dim]\n",
    "        decoder_hidden = decoder_hidden.repeat(1, encoder_outputs.size(1), 1)\n",
    "\n",
    "        combined = torch.cat([encoder_outputs, decoder_hidden], dim=2)  # [batch_size, seq_len, hidden_dim * 2]\n",
    "        scores = self.energy(combined).squeeze(2)  # [batch_size, seq_len]\n",
    "        \n",
    "        # 3: Áp dụng mask và softmax ( is it necessary)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e10)\n",
    "        attn_weights = F.softmax(scores, dim=1)    # [batch_size, seq_len]\n",
    "        \n",
    "        #  context = [batch_size, 1, hidden_dim]squeeze(1) loại chiều 1 -> [batch_size, hidden_dim]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1) \n",
    "    \n",
    "        return context, attn_weights\n",
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim=HIDDEN_DIM, vocab_size=vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTMCell(\n",
    "            input_size=self.embedding.embedding_dim + hidden_dim,  # Add context_dim\n",
    "            hidden_size=hidden_dim\n",
    "        )\n",
    "        self.attention = SimpleAttention(hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, vocab_size)  # Combine hidden + context\n",
    "\n",
    "    def forward(self, x, prev_hidden, prev_cell, encoder_outputs, mask=None):\n",
    "        x = self.embedding(x)  # [batch_size] -> [batch_size, emb_dim]\n",
    "        \n",
    "        if prev_hidden.dim() == 3:  # If it's [num_layers, batch_size, hidden_dim]\n",
    "            prev_hidden = prev_hidden[-1]  # Take last layer's hidden state\n",
    "        \n",
    "        context, attn_weights = self.attention(prev_hidden, encoder_outputs, mask)\n",
    "        \n",
    "        # Combine embedding and context to get input for LSTM\n",
    "        lstm_input = torch.cat([x, context], dim=1)  # [batch_size, emb_dim + hidden_dim]\n",
    "        \n",
    "        hidden, cell = self.lstm(lstm_input, (prev_hidden, prev_cell))\n",
    "        \n",
    "        # Kết hợp hidden và context để dự đoán từ\n",
    "        output_input = torch.cat([hidden, context], dim=1)\n",
    "        output = self.fc_out(output_input)\n",
    "        \n",
    "        return output, hidden, cell, attn_weights\n",
    "    \n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.encoder = SimpleEncoder(embedding_layer, hidden_dim)\n",
    "        self.decoder = SimpleDecoder(embedding_layer, hidden_dim, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.start_id = stoi(\"<SOS>\")  # Thêm start token ID\n",
    "\n",
    "    def forward(self, src, src_lens, trg=None, max_len=MAX_LENGTH_SUMMARY, teacher_forcing_ratio=0.5):\n",
    "        enc_outputs, (hidden, cell) = self.encoder(src, src_lens)\n",
    "        \n",
    "        batch_size = src.size(0)\n",
    "        if trg is None:\n",
    "            max_len = max_len\n",
    "            trg = torch.full((batch_size,), self.start_id, dtype=torch.long, device=src.device)\n",
    "        else:  # Training mode\n",
    "            max_len = trg.size(1)\n",
    "\n",
    "        outputs = torch.zeros(batch_size, max_len, self.vocab_size).to(src.device)\n",
    "\n",
    "        x = torch.full((batch_size,), self.start_id, dtype=torch.long, device=src.device)  # Đổi tên x_t -> x\n",
    "        \n",
    "        # Squeeze the encoder hidden states for the decoder\n",
    "        hidden = hidden.squeeze(0)  # [1, batch_size, hidden_dim] -> [batch_size, hidden_dim]\n",
    "        cell = cell.squeeze(0)\n",
    "        \n",
    "        for t in range(max_len):\n",
    "            output, hidden, cell, _ = self.decoder(\n",
    "                x=x,\n",
    "                prev_hidden=hidden,\n",
    "                prev_cell=cell,\n",
    "                encoder_outputs=enc_outputs\n",
    "            )\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            if trg is not None and random.random() < teacher_forcing_ratio:\n",
    "                x = trg[:, t]\n",
    "            else:\n",
    "                x = output.argmax(1)\n",
    "        \n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
