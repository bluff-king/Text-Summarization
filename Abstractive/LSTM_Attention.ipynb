{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "FRAC_SAMPLE = 0.1\n",
    "MAX_LENGTH_ARTICLE = 512\n",
    "MIN_LENGTH_ARTICLE = 50\n",
    "MAX_LENGTH_SUMMARY = 128\n",
    "MIN_LENGTH_SUMMARY = 20\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 0.0005\n",
    "NUM_CYCLES = 3\n",
    "MAX_PLATEAU_COUNT = 5\n",
    "WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_warmup_decay(step, warmup_steps, total_steps):\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / (warmup_steps + 1)\n",
    "    else:\n",
    "        return max(1e-7, (total_steps - step) / (total_steps - warmup_steps))\n",
    "\n",
    "\n",
    "def warmup_cosine_with_restarts(step, warmup_steps, total_steps, num_cycles=1):\n",
    "    if step < warmup_steps:\n",
    "        return (step + 1) / (warmup_steps + 1)\n",
    "    else:\n",
    "        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "        cycle_progress = progress * num_cycles % 1\n",
    "        return max(1e-7, 0.5 * (1 + math.cos(math.pi * cycle_progress)))\n",
    "\n",
    "\n",
    "\n",
    "def get_scheduler(\n",
    "    optimizer, total_steps, warmup_steps, num_cycles=None, types='warmup_cosine_with_restarts'\n",
    "):\n",
    "    if types == 'warmup_cosine_with_restarts':\n",
    "        assert num_cycles != None, 'must specify num_cycles when types=\"warmup_cosine_with_restarts\"'\n",
    "        return torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda step: warmup_cosine_with_restarts(\n",
    "                step, warmup_steps, total_steps, num_cycles=num_cycles)\n",
    "        )\n",
    "    elif types == 'linear_warmup_decay':\n",
    "        return torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda step: linear_warmup_decay(step, warmup_steps, total_steps)\n",
    "        )\n",
    "    else:\n",
    "        raise Exception('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../Model\"\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "validation_data = pd.read_csv(\"../dataset/validation.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "train_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "validation_data.rename(columns={\"highlights\": \"summaries\",\"article\":\"articles\"}, inplace=True)\n",
    "test_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"article_word_count\"] = train_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "train_data[\"summary_word_count\"] = train_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "validation_data[\"article_word_count\"] = validation_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "validation_data[\"summary_word_count\"] = validation_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "test_data[\"article_word_count\"] = test_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "test_data[\"summary_word_count\"] = test_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lọc train_data\n",
    "train_data = train_data[\n",
    "    (train_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (train_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (train_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (train_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "# Lọc validation_data\n",
    "validation_data = validation_data[\n",
    "    (validation_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (validation_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (validation_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (validation_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "# Lọc test_data\n",
    "test_data = test_data[\n",
    "    (test_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (test_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (test_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (test_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9599 entries, 144417 to 87788\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  9599 non-null   object\n",
      " 1   articles            9599 non-null   object\n",
      " 2   summaries           9599 non-null   object\n",
      " 3   article_word_count  9599 non-null   int64 \n",
      " 4   summary_word_count  9599 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 450.0+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 497 entries, 8901 to 12494\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  497 non-null    object\n",
      " 1   articles            497 non-null    object\n",
      " 2   summaries           497 non-null    object\n",
      " 3   article_word_count  497 non-null    int64 \n",
      " 4   summary_word_count  497 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 23.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sample = train_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "validation_sample = validation_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "test_sample = test_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "train_sample.info()\n",
    "print(\"\\n\")\n",
    "validation_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "max_len_article = train_sample[\"article_word_count\"].max()\n",
    "print(max_len_article)\n",
    "max_len_summary = train_sample[\"summary_word_count\"].max()\n",
    "print(max_len_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25004\n",
      "Embedding shape: (25004, 104)\n",
      "<PAD> embedding last 4 dims: [1.0, 0.0, 0.0, 0.0]\n",
      "<SOS> embedding last 4 dims: [0.0, 1.0, 0.0, 0.0]\n",
      "Word 'the' embedding last 4 dims: [0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = \"../Embedding/glove-wiki-gigaword-100.txt\"\n",
    "vocab, embeddings = [], []\n",
    "with open(EMBEDDING_FILE, 'rt', encoding='utf-8') as ef:\n",
    "    full_content = ef.read().strip().split('\\n')\n",
    "for i in range(len(full_content)):\n",
    "    i_word = full_content[i].split(' ')[0]\n",
    "    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "    i_embeddings.extend([0.0, 0.0, 0.0, 0.0])\n",
    "    vocab.append(i_word)\n",
    "    embeddings.append(i_embeddings)\n",
    "\n",
    "embs_npa = np.array(embeddings)\n",
    "\n",
    "unk_embedding = np.mean(embs_npa, axis=0).tolist()\n",
    "\n",
    "dim = embs_npa.shape[1]\n",
    "sos_embedding = [0.0] * dim\n",
    "sos_embedding[-3] = 1.0\n",
    "eos_embedding = [0.0] * dim\n",
    "eos_embedding[-2] = 1.0\n",
    "pad_embedding = [0.0] * dim\n",
    "pad_embedding[-4] = 1.0\n",
    "# unk_embedding = [0.0] * dim\n",
    "# unk_embedding[-1] = 1.0\n",
    "\n",
    "# Update vocab and embeddings\n",
    "vocab = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"] + vocab\n",
    "embeddings = [pad_embedding, sos_embedding,\n",
    "              eos_embedding, unk_embedding] + embeddings\n",
    "\n",
    "vocab_npa = np.array(vocab)\n",
    "embs_npa = np.array(embeddings)\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().strip().split()\n",
    "\n",
    "\n",
    "stoi_dict = {word: idx for idx, word in enumerate(vocab_npa)}\n",
    "_unk_idx = stoi_dict[\"<UNK>\"]\n",
    "\n",
    "\n",
    "def stoi(string, stoi_dict=stoi_dict):\n",
    "    return stoi_dict.get(string, _unk_idx)\n",
    "\n",
    "\n",
    "def numericalize(text):\n",
    "    tokenized_text = tokenize(text)\n",
    "    return [\n",
    "        stoi(token)\n",
    "        for token in tokenized_text\n",
    "    ]\n",
    "\n",
    "print(embs_npa.shape[0])\n",
    "embedding_layer = torch.nn.Embedding.from_pretrained(torch.FloatTensor(embeddings),\n",
    "                                                     freeze=False,\n",
    "                                                     padding_idx=stoi(\"<PAD>\"))\n",
    "embedding_layer.to(device)\n",
    "print(\"Embedding shape:\", np.array(embeddings).shape) \n",
    "print(\"<PAD> embedding last 4 dims:\", embeddings[stoi(\"<PAD>\")][-4:])\n",
    "print(\"<SOS> embedding last 4 dims:\", embeddings[stoi(\"<SOS>\")][-4:])\n",
    "print(\"Word 'the' embedding last 4 dims:\", embeddings[stoi(\"the\")][-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, articles, summaries, stoi, max_len_article=MAX_LENGTH_ARTICLE, max_len_summary=MAX_LENGTH_SUMMARY):\n",
    "        self.articles = articles  # List of articles\n",
    "        self.summaries = summaries  # List of summaries\n",
    "        self.stoi = stoi  # String-to-index dictionary\n",
    "        self.pad_idx = stoi(\"<PAD>\")\n",
    "        self.sos_idx = stoi(\"<SOS>\")\n",
    "        self.eos_idx = stoi(\"<EOS>\")\n",
    "        \n",
    "        # Determine max lengths if not provided\n",
    "        self.max_len_article = max_len_article or max(len(a.split()) for a in articles) + 2\n",
    "        self.max_len_summary = max_len_summary or max(len(s.split()) for s in summaries) + 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def process_text(text, max_len):\n",
    "            tokens = [self.sos_idx] + [self.stoi(w) for w in text.split()] + [self.eos_idx]  # Tokenize and add SOS/EOS\n",
    "            tokens = tokens[:max_len] + [self.pad_idx] * (max_len - len(tokens))  # Pad to max length\n",
    "            return torch.tensor(tokens), len(tokens)\n",
    "\n",
    "        article_tokens, article_len = process_text(self.articles[idx], self.max_len_article)\n",
    "        summary_tokens, summary_len = process_text(self.summaries[idx], self.max_len_summary)\n",
    "        \n",
    "        return {\n",
    "            'article': article_tokens,  # Encoded article\n",
    "            'article_len': torch.tensor(article_len),\n",
    "            'summary': summary_tokens,  # Encoded summary\n",
    "            'summary_len': torch.tensor(summary_len)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Batch is list os the dict {'article': ..., 'summary': ...}\n",
    "    return {\n",
    "        'article': torch.stack([item['article'] for item in batch]),\n",
    "        'article_len': torch.tensor([item['article_len'] for item in batch]),\n",
    "        'summary': torch.stack([item['summary'] for item in batch]),\n",
    "        'summary_len': torch.tensor([item['summary_len'] for item in batch])\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader setup\n",
    "# torch.set_printoptions(profile=\"full\")\n",
    "torch.set_printoptions(profile=\"default\")\n",
    "train_dataset = Seq2SeqDataset(train_sample['articles'].tolist(), train_sample['summaries'].tolist(), stoi)\n",
    "# print(train_dataset[268][\"article\"])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "valid_dataset= Seq2SeqDataset(validation_sample['articles'].tolist(), validation_sample['summaries'].tolist(), stoi)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Architecture Seq2Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim=HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer  # from_pretrained\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding.embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=False  # Unidirectional\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, seq_lens):  # x = batch input sequences\n",
    "        # 1: Embedding\n",
    "        x = self.embedding(x)  # [batch_size, max_len, emb_dim]\n",
    "        \n",
    "        # 2: Pack to ignore padding tokens\n",
    "        packed = pack_padded_sequence(\n",
    "            input=x,\n",
    "            lengths=seq_lens.cpu(),  # Chuyển sang CPU tensor\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False  # Không cần sắp xếp theo độ dài\n",
    "        )\n",
    "        \n",
    "        # 3: LSTM (chỉ xử lý độ dài thực) \n",
    "        '''\n",
    "        packed_output: dữ liệu thực sự được xử lý\n",
    "        hidden/cell lưu trạng thái cuối cùng của mỗi sequence\n",
    "        Input (padded):       Packed LSTM:         Output (unpacked):\n",
    "        [1,2,3,0,0]    -->   [1,2,3,4,5,6,7,8]       --> [h1_t1,h1_t2,h1_t3,0,0]\n",
    "        [4,5,6,7,8]     hidden_dim, hd,... hd(8cai)  --> [h2_t1,h2_t2,h2_t3,h2_t4,h2_t5]\n",
    "        '''\n",
    "        packed_output, (hidden, cell) = self.lstm(packed)\n",
    "        # Output: (batch_size, seq_len, hidden_dim)\n",
    "        # 4: Unpack to use attention \n",
    "        \n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        return output, (hidden, cell)  # hidden shape: [1, batch_size, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim=HIDDEN_DIM):\n",
    "        super().__init__()\n",
    "        # Kết hợp cả encoder outputs và decoder hidden state\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),  # Nhận input là [encoder_output + decoder_hidden]\n",
    "            nn.Tanh(),                              # thêm chút phi tuyến\n",
    "            nn.Linear(hidden_dim, 1, bias=False)    #  Trả về 1 chiều attention scores\n",
    "        )\n",
    "    \n",
    "    def forward(self, decoder_hidden, encoder_outputs, mask=None):\n",
    "        # 1: Prepare decoder_hidden to + encoder_outputs\n",
    "        # decoder_hidden: [batch_size, hidden_dim]\n",
    "        # encoder_outputs: [batch_size, seq_len, hidden_dim]\n",
    "        # Copy dọc theo seq_len\n",
    "        #########  decoder_hidden = decoder_hidden.unsqueeze(1).expand_as(encoder_outputs)  # [batch_size, seq_len, hidden_dim]\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1)  # [batch_size, 1, hidden_dim]\n",
    "        decoder_hidden = decoder_hidden.repeat(1, encoder_outputs.size(1), 1)\n",
    "        # 2: Calculate energy from encoder-decoder combination\n",
    "        combined = torch.cat([encoder_outputs, decoder_hidden], dim=2)  # [batch_size, seq_len, hidden_dim * 2]\n",
    "        scores = self.energy(combined).squeeze(2)  # [batch_size, seq_len]\n",
    "        \n",
    "        # 3: Áp dụng mask và softmax\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e10)\n",
    "        attn_weights = F.softmax(scores, dim=1)    # [batch_size, seq_len]\n",
    "        \n",
    "        # 4: Calculate context vector: # [batch_size,1, hidden_dim] x [batch_size, seq_len, hidden_dim]\n",
    "                    #  context = [batch_size, 1, hidden_dim]squeeze(1) loại chiều 1 -> [batch_size, hidden_dim]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1) \n",
    "     \n",
    "        # debug  \n",
    "        '''\n",
    "        Encoder Outputs:  \"<SOS>\"   \"cat\"    \"sat\"   \"<EOS>\"  \"<PAD>\"\n",
    "                        [0.1,0.2] [0.3,0.4] [0.5,0.6] [0.7,0.8] [0.0,0.0]\n",
    "        Attention Weights:  0.12      0.53      0.29      0.06      0.0\n",
    "                        ↓         ↓         ↓         ↓         ↓\n",
    "        Context Vector:  = 0.12*[0.1,0.2] + 0.53*[0.3,0.4] + ... = [0.35, 0.45]\n",
    "        '''\n",
    "        '''\n",
    "        attn_weights (unsqueezed):   encoder_outputs:       context:\n",
    "        [ [ [0.2, 0.5, 0.3] ]    @  [[0.1,0.2],        =  [ [0.32, 0.42] ]\n",
    "        [ [0.1, 0.7, 0.2] ]        [0.3,0.4],            [0.92, 1.02] ]\n",
    "                                    [0.5,0.6] ]\n",
    "        '''\n",
    "        # print(\"Decoder hidden:\", decoder_hidden.shape)\n",
    "        # print(\"Encoder outputs:\", encoder_outputs.shape)\n",
    "        # context, attn_weights = self.attention(decoder_hidden, encoder_outputs)\n",
    "        # print(\"Attention weights:\", attn_weights)  # Which part has high attention\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim=HIDDEN_DIM, vocab_size=vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTMCell(\n",
    "            input_size=self.embedding.embedding_dim + hidden_dim,  # Add context_dim\n",
    "            hidden_size=hidden_dim\n",
    "        )\n",
    "        self.attention = SimpleAttention(hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, vocab_size)  # Combine hidden + context\n",
    "\n",
    "    def forward(self, x, prev_hidden, prev_cell, encoder_outputs, mask=None):\n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # [batch_size] -> [batch_size, emb_dim]\n",
    "        \n",
    "        if prev_hidden.dim() == 3:  # If it's [num_layers, batch_size, hidden_dim]\n",
    "            prev_hidden = prev_hidden[-1]  # Take last layer's hidden state\n",
    "        \n",
    "        context, attn_weights = self.attention(prev_hidden, encoder_outputs, mask)\n",
    "        \n",
    "        # Combine embedding and context to get input for LSTM\n",
    "        lstm_input = torch.cat([x, context], dim=1)  # [batch_size, emb_dim + hidden_dim]\n",
    "        \n",
    "        # LSTM step\n",
    "        hidden, cell = self.lstm(lstm_input, (prev_hidden, prev_cell))\n",
    "        \n",
    "        # Kết hợp hidden và context để dự đoán từ\n",
    "        output_input = torch.cat([hidden, context], dim=1)\n",
    "        output = self.fc_out(output_input)\n",
    "        \n",
    "        return output, hidden, cell, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, embedding_layer, hidden_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.encoder = SimpleEncoder(embedding_layer, hidden_dim)\n",
    "        self.decoder = SimpleDecoder(embedding_layer, hidden_dim, vocab_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.start_id = stoi(\"<SOS>\")  # Thêm start token ID\n",
    "\n",
    "    def forward(self, src, src_lens, trg=None, max_len=256, teacher_forcing_ratio=0.5):\n",
    "        # Encoder forward\n",
    "        enc_outputs, (hidden, cell) = self.encoder(src, src_lens)\n",
    "        \n",
    "        # Chuẩn bị decoder\n",
    "        batch_size = src.size(0)\n",
    "        if trg is None:  # Inference mode\n",
    "            max_len = max_len\n",
    "            trg = torch.full((batch_size,), self.start_id, dtype=torch.long, device=src.device)\n",
    "        else:  # Training mode\n",
    "            max_len = trg.size(1)\n",
    "        \n",
    "        # Tensor lưu outputs\n",
    "        outputs = torch.zeros(batch_size, max_len, self.vocab_size).to(src.device)\n",
    "        \n",
    "        # Khởi tạo input đầu tiên\n",
    "        x = torch.full((batch_size,), self.start_id, dtype=torch.long, device=src.device)  # Đổi tên x_t -> x\n",
    "        \n",
    "        # Squeeze the encoder hidden states for the decoder\n",
    "        hidden = hidden.squeeze(0)  # [1, batch_size, hidden_dim] -> [batch_size, hidden_dim]\n",
    "        cell = cell.squeeze(0)\n",
    "        \n",
    "        for t in range(max_len):\n",
    "            output, hidden, cell, _ = self.decoder(\n",
    "                x=x,\n",
    "                prev_hidden=hidden,\n",
    "                prev_cell=cell,\n",
    "                encoder_outputs=enc_outputs\n",
    "            )\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            if trg is not None and random.random() < teacher_forcing_ratio:\n",
    "                x = trg[:, t]\n",
    "            else:\n",
    "                x = output.argmax(1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory allocated: 9.92 MB\n",
      "GPU Memory reserved: 20.00 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU Memory allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "print(f\"GPU Memory reserved: {torch.cuda.memory_reserved()/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([25004, 104])\n",
      "Vocab size: 25004\n",
      "Model architecture:\n",
      "Seq2SeqModel(\n",
      "  (encoder): SimpleEncoder(\n",
      "    (embedding): Embedding(25004, 104, padding_idx=0)\n",
      "    (lstm): LSTM(104, 128, batch_first=True)\n",
      "  )\n",
      "  (decoder): SimpleDecoder(\n",
      "    (embedding): Embedding(25004, 104, padding_idx=0)\n",
      "    (lstm): LSTMCell(232, 128)\n",
      "    (attention): SimpleAttention(\n",
      "      (energy): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Linear(in_features=128, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (fc_out): Linear(in_features=256, out_features=25004, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embedding_layer = torch.nn.Embedding.from_pretrained(\n",
    "    torch.FloatTensor(embeddings),\n",
    "    freeze=False,  # Cho phép fine-tune embedding\n",
    "    padding_idx=stoi(\"<PAD>\")  # Index của token padding\n",
    ").to(device)\n",
    "\n",
    "# Khởi tạo\n",
    "vocab_size = len(vocab)\n",
    "model = Seq2SeqModel(\n",
    "    embedding_layer=embedding_layer,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "print(\"Embedding shape:\", torch.FloatTensor(embeddings).shape)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvubkk67\u001b[0m (\u001b[33mvubkk67-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vuda/Text-Summarization/Abstractive/wandb/run-20250405_213657-91ll2a44</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/91ll2a44' target=\"_blank\">seq2seq-20250405-213656</a></strong> to <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/91ll2a44' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/91ll2a44</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Seq2Seq-Summarization/runs/91ll2a44?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9bf0a03c20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Seq2Seq-Summarization\",\n",
    "    name=f\"seq2seq-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"model\": \"Seq2Seq-LSTM\",\n",
    "        \"hidden_dim\": HIDDEN_DIM,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"teacher_forcing_ratio\": 0.5,\n",
    "        \"vocab_size\": len(vocab)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, lr_scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        src = batch['article'].to(device)\n",
    "        src_lens = batch['article_len'].to(device)\n",
    "        trg = batch['summary'].to(device)\n",
    "        \n",
    "        outputs = model(src, src_lens, trg=trg, teacher_forcing_ratio=0.5)\n",
    "        loss = criterion(\n",
    "            outputs[:, 1:].reshape(-1, outputs.size(-1)),\n",
    "            trg[:, 1:].reshape(-1)\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   #prevent gradient exploding\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        # progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# 3. Hàm eval với progress bar\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            src = batch['article'].to(device)\n",
    "            src_lens = batch['article_len'].to(device)\n",
    "            trg = batch['summary'].to(device)\n",
    "            \n",
    "            outputs = model(src, src_lens, trg=trg, teacher_forcing_ratio=0)\n",
    "            loss = criterion(\n",
    "                outputs[:, 1:].reshape(-1, outputs.size(-1)),\n",
    "                trg[:, 1:].reshape(-1)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            # progress_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return total_loss / len(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee493c20a7e0460687bfa64b763c645e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916e24d110a8430c935c33a952d1a3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 7.0976 | Val Loss: 5.3050 | LR: 0.000167 | Time: 449.07s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac79096908044785a84c102e66379073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aa7842716641c8b98c5c7b3845f398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 5.3667 | Val Loss: 5.3010 | LR: 0.000333 | Time: 447.44s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12115c6b439849889e2bf254472ec0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ab75fc11c84579bcb9b43df12fe9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 5.3011 | Val Loss: 5.2948 | LR: 0.000500 | Time: 447.89s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473dbe05f82b4f819a53ea9e4a9abf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3b5c18dd7f4b7f8ff90e47e2ac2504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 5.2126 | Val Loss: 5.2440 | LR: 0.000485 | Time: 448.73s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247d381ad7364bc08ee6f20175735c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f22df9f8f2f45ffaa216d441dfae249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 5.1333 | Val Loss: 5.1705 | LR: 0.000442 | Time: 447.79s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045475c5711b42d694bb6698063e664d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f722bc5fe431498f8bc17ae97ffc1897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 5.0800 | Val Loss: 5.1362 | LR: 0.000375 | Time: 448.01s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667fe3748134d2abd7f1d5b33de27fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa56f9d4b3b41fbae0f3ef53cf8543b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 5.0383 | Val Loss: 5.1845 | LR: 0.000293 | Time: 448.74s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f837d4804b4fa4a08158a2483cb754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fd514b527d421abcd4d4f46518904a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 5.0157 | Val Loss: 5.1319 | LR: 0.000207 | Time: 449.56s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e69909bf8e451b82afef9090cac203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2753cdbc40481a9a9dec20d085407c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 4.9917 | Val Loss: 5.1287 | LR: 0.000125 | Time: 451.91s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec95adcaf6d64d84baa1829f2b8deaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save best Model\n",
    "best_model_path = os.path.join(model_dir, \"best_model.pth\")\n",
    "embedding_layer = torch.nn.Embedding.from_pretrained(\n",
    "    torch.FloatTensor(embeddings),\n",
    "    freeze=False,\n",
    "    padding_idx=stoi(\"<PAD>\")\n",
    ").to(device)\n",
    "\n",
    "# 3. Khởi tạo model\n",
    "model = Seq2SeqModel(\n",
    "    embedding_layer=embedding_layer,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "\n",
    "# 4. Train loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi(\"<PAD>\"))\n",
    "best_val_loss = float('inf')\n",
    "# Initialize learning rate scheduler\n",
    "total_steps = NUM_EPOCHS * len(train_loader)\n",
    "warmup_steps = int(0.1 * total_steps)  # 10% of total steps for warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    optimizer, \n",
    "    total_steps=total_steps,\n",
    "    warmup_steps=warmup_steps,\n",
    "    num_cycles=NUM_CYCLES\n",
    ")\n",
    "plateau_count = 0\n",
    "wandb.watch(model)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion, device,lr_scheduler)\n",
    "    \n",
    "    # Eval\n",
    "    val_loss = evaluate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    current_lr = lr_scheduler.get_last_lr()[0] if lr_scheduler else LEARNING_RATE\n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch+1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"best_val_loss\": best_val_loss, \n",
    "        \"lr\": current_lr\n",
    "    })\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        plateau_count = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler_state_dict': lr_scheduler.state_dict() if lr_scheduler else None,\n",
    "        }, best_model_path)\n",
    "    else:\n",
    "        plateau_count += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"LR: {current_lr:.6f} | \"\n",
    "          f\"Time: {time.time()-start_time:.2f}s\")\n",
    "    \n",
    "    # Early stopping if validation loss doesn't improve\n",
    "    if plateau_count >= MAX_PLATEAU_COUNT:\n",
    "        print(f\"Validation loss hasn't improved for {MAX_PLATEAU_COUNT} epochs. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# Kết thúc W&B\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
