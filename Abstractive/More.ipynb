{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from rouge import Rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 8\n",
    "FRAC_SAMPLE = 0.005\n",
    "MAX_LENGTH_ARTICLE = 512\n",
    "MIN_LENGTH_ARTICLE = 50\n",
    "MAX_LENGTH_SUMMARY = 128\n",
    "MIN_LENGTH_SUMMARY = 20\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_PLATEAU_COUNT = 7\n",
    "WEIGHT_DECAY = 1e-4\n",
    "CLIP = 1\n",
    "USE_PRETRAINED_EMB = True\n",
    "USE_SCHEDULER = True\n",
    "SCHEDULER_TYPE = \"plateau\"  # hoáº·c cosine, linear\n",
    "NUM_CYCLES = 7\n",
    "\n",
    "\n",
    "model_dir = \"../Model\"\n",
    "datafilter = \"../dataft\"\n",
    "save_dir = \"fine_tuned_bart_cosine_3\"\n",
    "output_path = os.path.join(datafilter, \"test_pred_3.csv\")\n",
    "os.makedirs(datafilter, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "validation_data = pd.read_csv(\"../dataset/validation.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "# add col\n",
    "train_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "validation_data.rename(columns={\"highlights\": \"summaries\",\"article\":\"articles\"}, inplace=True)\n",
    "test_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "\n",
    "train_data[\"article_word_count\"] = train_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "train_data[\"summary_word_count\"] = train_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "validation_data[\"article_word_count\"] = validation_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "validation_data[\"summary_word_count\"] = validation_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "test_data[\"article_word_count\"] = test_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "test_data[\"summary_word_count\"] = test_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# filter range\n",
    "train_data = train_data[\n",
    "    (train_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (train_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (train_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (train_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "validation_data = validation_data[\n",
    "    (validation_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (validation_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (validation_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (validation_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "test_data = test_data[\n",
    "    (test_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (test_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (test_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (test_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "train_sample = train_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "validation_sample = validation_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "test_sample = test_data.sample(frac=1, random_state=1)\n",
    "train_sample.info()\n",
    "print(\"\\n\")\n",
    "validation_sample.info()\n",
    "train_sample.to_csv(os.path.join(datafilter,\"train_sample.csv\"), index=False)\n",
    "test_sample.to_csv(os.path.join(datafilter,\"test_sample.csv\"), index=False)\n",
    "validation_sample.to_csv(os.path.join(datafilter,\"validation_sample.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19198 entries, 0 to 19197\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  19198 non-null  object\n",
      " 1   articles            19198 non-null  object\n",
      " 2   summaries           19198 non-null  object\n",
      " 3   article_word_count  19198 non-null  int64 \n",
      " 4   summary_word_count  19198 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 750.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sample = pd.read_csv(\"../dataft/train_sample.csv\")\n",
    "validation_sample = pd.read_csv(\"../dataft/validation_sample.csv\")\n",
    "test_sample = pd.read_csv(\"../dataft/test_sample.csv\")\n",
    "train_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_length=MAX_LENGTH_ARTICLE, max_output_length=MAX_LENGTH_SUMMARY):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        article = self.data.iloc[index][\"articles\"]\n",
    "        summary = self.data.iloc[index][\"summaries\"]\n",
    "        input_ids = self.tokenizer.encode(article, max_length=self.max_input_length, truncation=True, padding=\"max_length\")\n",
    "        output_ids = self.tokenizer.encode(summary, max_length=self.max_output_length, truncation=True, padding=\"max_length\")\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": [int(token_id != 0) for token_id in input_ids], \"decoder_input_ids\": output_ids[:-1], \"decoder_attention_mask\": [1] * (len(output_ids) - 1), \"labels\": output_ids[1:]}\n",
    "train_df = train_sample\n",
    "test_df = test_sample\n",
    "val_df = validation_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummarizationDataset(train_df, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    decoder_input_ids = [item[\"decoder_input_ids\"] for item in batch]\n",
    "    decoder_attention_mask = [item[\"decoder_attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    max_input_length = max(len(ids) for ids in input_ids)\n",
    "    max_output_length = max(len(ids) for ids in decoder_input_ids)\n",
    "    input_ids = [ids + [0] * (max_input_length - len(ids)) for ids in input_ids]\n",
    "    attention_mask = [mask + [0] * (max_input_length - len(mask)) for mask in attention_mask]\n",
    "    decoder_input_ids = [ids + [0] * (max_output_length - len(ids)) for ids in decoder_input_ids]\n",
    "    decoder_attention_mask = [mask + [0] * (max_output_length - len(mask)) for mask in decoder_attention_mask]\n",
    "    labels = [ids + [-100] * (max_output_length - len(ids)) for ids in labels]\n",
    "    return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "num_training_steps = (len(train_loader) * NUM_EPOCHS)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=num_training_steps,\n",
    "    num_cycles=NUM_CYCLES \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader),len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvubkk67\u001b[0m (\u001b[33mvubkk67-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vuda/Text-Summarization/Abstractive/wandb/run-20250410_131040-qhya52qk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/qhya52qk' target=\"_blank\">bartbase-20250410-131040</a></strong> to <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/qhya52qk' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/qhya52qk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/qhya52qk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5e20730b90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Finetune-Summarization\",\n",
    "    name=f\"bartbase-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"model\": \"Bartbase_cosine_3\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"num_cycles\": NUM_CYCLES,\n",
    "        \"data_ratio\": FRAC_SAMPLE,\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c272247bd14115ab0ff2d6e2d75459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c6e3f581f8478cb12dd17dbdc6fa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuda/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:3353: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart` at epoch 1\n",
      "Epoch 01 | Train Loss: 1.5771 | Val Loss: 0.9106 | LR: 0.000040 | Time: 4116.16s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239a0b9bbfa04d32932accd33279a4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dce552b2164f46a291031bbf6a0023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart` at epoch 2\n",
      "Epoch 02 | Train Loss: 0.8859 | Val Loss: 0.8841 | LR: 0.000027 | Time: 4098.80s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b3563288ed40de82483c7d04d83fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501bc906bd2342698372f1d3317e905c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart` at epoch 3\n",
      "Epoch 03 | Train Loss: 0.7899 | Val Loss: 0.8580 | LR: 0.000015 | Time: 4080.54s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84529d6f81443098af85d598700465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866566ed29d143bea951b89788d47f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_bart` at epoch 4\n",
      "Epoch 04 | Train Loss: 0.7173 | Val Loss: 0.8447 | LR: 0.000002 | Time: 4084.26s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3459ffb2aa2a4a5b8c5b63521769deba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06898e3a27214979bb7a96d512af6fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 0.6793 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4063.83s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a26f90d928f44c1ac105ac18e045722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7db49957c344c78467669afb4b4812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 0.6790 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4064.70s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409da0a62d20403fa00371ddb6fae7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2d93aca6dc4f89aee541559ec0b489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 0.6788 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4071.02s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf3c3c01d247cdbf054b95b5664295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f032cbb5da4093929b67a30c35824d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 0.6787 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4059.81s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a866b66df36b4d88bc40f76d5c28ae9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a971fe190343adb13b330698319c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 0.6792 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4057.35s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a1b4782df04673aa135bd9c2eb9994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ab0b2260b34727936f342da931ad0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6793 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4057.46s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdd081a56564acd8a520bd48ac7900e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a64fb63121d4ed9a58abca74c7acf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6788 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4058.10s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1f61fe668942809c22f6a5676c939a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18b08d8c497409598ff31ed3ae22cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6783 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4054.64s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db6d00be08443febb116ba120463f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980d0ff22fef44d18a7d8ea99c12d1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6789 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4051.47s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b90d234346499dac65663acee09f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a7e7a7fca940ef95a702efef867eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6789 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4051.31s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235f755bd2f842a3a29d2ca6062b90a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f664ceca4b8644bd8fa18f98e85b0869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6793 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4050.04s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8009d0e228a4f7f98c48efdc387a870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d53478ab2954c03abb3611a645d437c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.6788 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4050.63s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c04ca96f0648de8cc0b8891e0c1287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8703f4de97346dcb8abd304a93f6d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6789 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4051.43s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c598644aafc462995b251bc5094975d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b6830149984739bf7d44479f9a29c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 [Val]:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6795 | Val Loss: 0.8482 | LR: 0.000000 | Time: 4051.82s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e081bc5b9342778aca22529b0de4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 [Train]:   0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save best model\n",
    "best_val_loss = float(\"inf\")\n",
    "# W&B setup\n",
    "wandb.watch(model)\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}  # ThÃªm dÃ²ng nÃ y\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    # W&B log\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"lr\": current_lr,\n",
    "        \"best_val_loss\": best_val_loss\n",
    "    })\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model.save_pretrained(save_dir)\n",
    "        tokenizer.save_pretrained(save_dir)\n",
    "        print(f\"Saved best model to `{save_dir}` at epoch {epoch+1}\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"LR: {current_lr:.6f} | \"\n",
    "        f\"Time: {time.time() - start_time:.2f}s\"\n",
    "    )\n",
    "\n",
    "# W&B end\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = PegasusTokenizer.from_pretrained(save_dir)\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(save_dir).to(device)\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(save_dir)\n",
    "model = BartForConditionalGeneration.from_pretrained(save_dir).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2532"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = SummarizationDataset(test_df, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,collate_fn=collate_fn)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428a69bbcd8a4839a5ad87f2c00a5e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating summaries:   0%|          | 0/2532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â File ÄÃ£ ÄÆ°á»£c lÆ°u táº¡i: ../dataft/test_sample.csv\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(test_loader, desc=\"Generating summaries\")):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        output_ids = model.generate(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            max_length=128,\n",
    "            decoder_start_token_id=tokenizer.pad_token_id,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        batch_preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        predictions.extend(batch_preds)\n",
    "test_sample = test_sample.iloc[:len(predictions)].copy()\n",
    "test_sample[\"predicted_summary\"] = predictions\n",
    "test_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"â File has been saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>predicted_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supermarket giant Coles has been ordered to pa...</td>\n",
       "      <td>Coles ordered to pay $2.5 million in penalties...</td>\n",
       "      <td>Supermarket giant Coles has been ordered to pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSV Eindhoven beat Heerenveen 4-1 to win the D...</td>\n",
       "      <td>PSV beat Heerenveen to lift their first Erediv...</td>\n",
       "      <td>PSV Eindhoven beat Heerenveen 4-1 on Saturday...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles  \\\n",
       "0  Supermarket giant Coles has been ordered to pa...   \n",
       "1  PSV Eindhoven beat Heerenveen 4-1 to win the D...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Coles ordered to pay $2.5 million in penalties...   \n",
       "1  PSV beat Heerenveen to lift their first Erediv...   \n",
       "\n",
       "                                   predicted_summary  \n",
       "0  Supermarket giant Coles has been ordered to pa...  \n",
       "1   PSV Eindhoven beat Heerenveen 4-1 on Saturday...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_pred[[\"articles\",\"summaries\", \"predicted_summary\"]].head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ð¯ ROUGE scores:\n",
      "ROUGE-1: 0.3800\n",
      "ROUGE-2: 0.1634\n",
      "ROUGE-L: 0.3549\n"
     ]
    }
   ],
   "source": [
    "# TÃ­nh Äiá»m ROUGE\n",
    "if \"summaries\" in test_pred.columns:\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predictions, test_sample[\"summaries\"].tolist(), avg=True)\n",
    "\n",
    "    print(\"ROUGE scores:\")\n",
    "    print(f\"ROUGE-1: {scores['rouge-1']['f']:.4f}\")\n",
    "    print(f\"ROUGE-2: {scores['rouge-2']['f']:.4f}\")\n",
    "    print(f\"ROUGE-L: {scores['rouge-l']['f']:.4f}\")\n",
    "else:\n",
    "    print(\"â ï¸ KhÃ´ng tÃ¬m tháº¥y cá»t 'summaries' Äá» tÃ­nh ROUGE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
