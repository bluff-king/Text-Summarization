{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:33:34.880318: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-10 12:33:35.523194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746855215.745438   74018 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746855215.810543   74018 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746855216.335558   74018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746855216.335686   74018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746855216.335689   74018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746855216.335690   74018 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-10 12:33:36.396882: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import time\n",
    "import os\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, PegasusConfig, get_cosine_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from rouge import Rouge\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "FRAC_SAMPLE = 0.2\n",
    "MAX_LENGTH_ARTICLE = 512\n",
    "MIN_LENGTH_ARTICLE = 50\n",
    "MAX_LENGTH_SUMMARY = 128\n",
    "MIN_LENGTH_SUMMARY = 20\n",
    "HIDDEN_DIM = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 5  # For early stopping\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_CYCLES = 5\n",
    "\n",
    "\n",
    "# model_dir = \"../Model\"\n",
    "datafilter = \"../dataft\"\n",
    "save_dir = \"fine_tuned_pegasus_custom\"\n",
    "output_path = os.path.join(datafilter, \"test_pred_5.csv\")\n",
    "os.makedirs(datafilter, exist_ok=True)\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19198 entries, 144417 to 201560\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  19198 non-null  object\n",
      " 1   articles            19198 non-null  object\n",
      " 2   summaries           19198 non-null  object\n",
      " 3   article_word_count  19198 non-null  int64 \n",
      " 4   summary_word_count  19198 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 899.9+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 994 entries, 8901 to 8365\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  994 non-null    object\n",
      " 1   articles            994 non-null    object\n",
      " 2   summaries           994 non-null    object\n",
      " 3   article_word_count  994 non-null    int64 \n",
      " 4   summary_word_count  994 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 46.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/train.csv\")\n",
    "validation_data = pd.read_csv(\"../dataset/validation.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "# add col\n",
    "train_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "validation_data.rename(columns={\"highlights\": \"summaries\",\"article\":\"articles\"}, inplace=True)\n",
    "test_data.rename(columns={\"highlights\": \"summaries\", \"article\":\"articles\"}, inplace=True)\n",
    "\n",
    "train_data[\"article_word_count\"] = train_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "train_data[\"summary_word_count\"] = train_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "validation_data[\"article_word_count\"] = validation_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "validation_data[\"summary_word_count\"] = validation_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "test_data[\"article_word_count\"] = test_data[\"articles\"].astype(str).apply(lambda x: len(x.split()))\n",
    "test_data[\"summary_word_count\"] = test_data[\"summaries\"].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "# filter range\n",
    "train_data = train_data[\n",
    "    (train_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (train_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (train_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (train_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "validation_data = validation_data[\n",
    "    (validation_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (validation_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (validation_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (validation_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "test_data = test_data[\n",
    "    (test_data[\"article_word_count\"] <= MAX_LENGTH_ARTICLE) & \n",
    "    (test_data[\"article_word_count\"] >= MIN_LENGTH_ARTICLE) &\n",
    "    (test_data[\"summary_word_count\"] <= MAX_LENGTH_SUMMARY) &\n",
    "    (test_data[\"summary_word_count\"] >= MIN_LENGTH_SUMMARY)\n",
    "]\n",
    "\n",
    "train_sample = train_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "validation_sample = validation_data.sample(frac=FRAC_SAMPLE, random_state=1)\n",
    "test_sample = test_data.sample(frac=1, random_state=1)\n",
    "train_sample.info()\n",
    "print(\"\\n\")\n",
    "validation_sample.info()\n",
    "train_sample.to_csv(os.path.join(datafilter,\"train_sample.csv\"), index=False)\n",
    "test_sample.to_csv(os.path.join(datafilter,\"test_sample.csv\"), index=False)\n",
    "validation_sample.to_csv(os.path.join(datafilter,\"validation_sample.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19198 entries, 0 to 19197\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  19198 non-null  object\n",
      " 1   articles            19198 non-null  object\n",
      " 2   summaries           19198 non-null  object\n",
      " 3   article_word_count  19198 non-null  int64 \n",
      " 4   summary_word_count  19198 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 750.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_sample = pd.read_csv(\"../dataft/train_sample.csv\")\n",
    "validation_sample = pd.read_csv(\"../dataft/validation_sample.csv\")\n",
    "test_sample = pd.read_csv(\"../dataft/test_sample.csv\")\n",
    "train_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PegasusForConditionalGeneration(\n",
       "  (model): PegasusModel(\n",
       "    (shared): Embedding(96103, 512, padding_idx=0)\n",
       "    (encoder): PegasusEncoder(\n",
       "      (embed_tokens): Embedding(96103, 512, padding_idx=0)\n",
       "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x PegasusEncoderLayer(\n",
       "          (self_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): PegasusDecoder(\n",
       "      (embed_tokens): Embedding(96103, 512, padding_idx=0)\n",
       "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x PegasusDecoderLayer(\n",
       "          (self_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PegasusAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=96103, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "# tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
    "# model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-large').to(device)\n",
    "# from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "# import torch\n",
    "\n",
    "\n",
    "# # Hiển thị tổng số tham số và trainable parameters\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# print(f\"🔢 Total parameters: {total_params:,}\")\n",
    "# print(f\"🧠 Trainable parameters: {trainable_params:,}\\n\")\n",
    "\n",
    "from transformers import PegasusConfig, PegasusForConditionalGeneration\n",
    "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-large')\n",
    "config = PegasusConfig(\n",
    "    vocab_size=96103,  # bắt buộc khớp tokenizer\n",
    "    max_position_embeddings=512,\n",
    "    encoder_layers=6,           # giảm so với 16 (pegasus-large)\n",
    "    decoder_layers=6,\n",
    "    encoder_attention_heads=8,\n",
    "    decoder_attention_heads=8,\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    dropout=0.1,\n",
    "    attention_dropout=0.1,\n",
    "    activation_dropout=0.1,\n",
    "    init_std=0.02,\n",
    "    scale_embedding=True,\n",
    "    use_cache=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "model = PegasusForConditionalGeneration(config)\n",
    "model.resize_token_embeddings(len(tokenizer))  # quan trọng nếu tokenizer được tùy biến\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_length=MAX_LENGTH_ARTICLE, max_output_length=MAX_LENGTH_SUMMARY):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_output_length = max_output_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        article = self.data.iloc[index][\"articles\"]\n",
    "        summary = self.data.iloc[index][\"summaries\"]\n",
    "        input_ids = self.tokenizer.encode(article, max_length=self.max_input_length, truncation=True, padding=\"max_length\")\n",
    "        output_ids = self.tokenizer.encode(summary, max_length=self.max_output_length, truncation=True, padding=\"max_length\")\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": [int(token_id != 0) for token_id in input_ids], \"decoder_input_ids\": output_ids[:-1], \"decoder_attention_mask\": [1] * (len(output_ids) - 1), \"labels\": output_ids[1:]}\n",
    "train_df = train_sample\n",
    "test_df = test_sample\n",
    "val_df = validation_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SummarizationDataset(train_df, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_df, tokenizer)\n",
    "test_dataset = SummarizationDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    decoder_input_ids = [item[\"decoder_input_ids\"] for item in batch]\n",
    "    decoder_attention_mask = [item[\"decoder_attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    max_input_length = max(len(ids) for ids in input_ids)\n",
    "    max_output_length = max(len(ids) for ids in decoder_input_ids)\n",
    "    input_ids = [ids + [0] * (max_input_length - len(ids)) for ids in input_ids]\n",
    "    attention_mask = [mask + [0] * (max_input_length - len(mask)) for mask in attention_mask]\n",
    "    decoder_input_ids = [ids + [0] * (max_output_length - len(ids)) for ids in decoder_input_ids]\n",
    "    decoder_attention_mask = [mask + [0] * (max_output_length - len(mask)) for mask in decoder_attention_mask]\n",
    "    labels = [ids + [-100] * (max_output_length - len(ids)) for ids in labels]\n",
    "    \n",
    "    labels = torch.tensor(labels)\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    \n",
    "    return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n",
    "# def collate_fn(batch):\n",
    "#     input_ids = [item[\"input_ids\"] for item in batch]\n",
    "#     attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "#     labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "#     max_input_length = max(len(ids) for ids in input_ids)\n",
    "#     max_output_length = max(len(lab) for lab in labels)\n",
    "\n",
    "#     def pad(seq, max_len, pad_value):\n",
    "#         return seq + [pad_value] * (max_len - len(seq))\n",
    "\n",
    "#     input_ids = torch.tensor([pad(ids, max_input_length, tokenizer.pad_token_id) for ids in input_ids])\n",
    "#     attention_mask = torch.tensor([pad(mask, max_input_length, 0) for mask in attention_mask])\n",
    "#     labels = torch.tensor([pad(lab, max_output_length, -100) for lab in labels])\n",
    "\n",
    "#     return {\n",
    "#         \"input_ids\": input_ids,\n",
    "#         \"attention_mask\": attention_mask,\n",
    "#         \"labels\": labels\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_decay = ['bias', 'LayerNorm.weight']    # cần ít regularization hơn weight\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {\n",
    "#         'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "#         'weight_decay': WEIGHT_DECAY,\n",
    "#     },\n",
    "#     {\n",
    "#         'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "#         'weight_decay': 0.0,\n",
    "#     },\n",
    "# ]\n",
    "# # optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n",
    "\n",
    "# # Scheduler\n",
    "# num_training_steps = len(train_loader) * NUM_EPOCHS\n",
    "# # scheduler = get_cosine_schedule_with_warmup(\n",
    "# #     optimizer,\n",
    "# #     num_warmup_steps=int(0.2 * num_training_steps),\n",
    "# #     num_training_steps=num_training_steps,\n",
    "# #     num_cycles=NUM_CYCLES\n",
    "# # )\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "# Scheduler\n",
    "num_training_steps = len(train_loader) * NUM_EPOCHS\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.2 * num_training_steps),\n",
    "    num_training_steps=num_training_steps,\n",
    "    num_cycles=NUM_CYCLES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add custom scheduler class (place this at the top of your script)\n",
    "# class CosineWarmupWithBounds(_LRScheduler):\n",
    "#     def __init__(self, optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5, max_lr=1e-4, min_lr=1e-5, last_epoch=-1):\n",
    "#         self.num_warmup_steps = num_warmup_steps\n",
    "#         self.num_training_steps = num_training_steps\n",
    "#         self.num_cycles = num_cycles\n",
    "#         self.max_lr = max_lr\n",
    "#         self.min_lr = min_lr\n",
    "#         super(CosineWarmupWithBounds, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "#     def get_lr(self):\n",
    "#         step = self.last_epoch + 1\n",
    "#         if step < self.num_warmup_steps:\n",
    "#             lr = self.min_lr + (self.max_lr - self.min_lr) * step / self.num_warmup_steps\n",
    "#         else:\n",
    "#             progress = (step - self.num_warmup_steps) / (self.num_training_steps - self.num_warmup_steps)\n",
    "#             cosine_factor = 0.5 * (1.0 + math.cos(math.pi * progress * self.num_cycles))\n",
    "#             lr = self.min_lr + (self.max_lr - self.min_lr) * cosine_factor\n",
    "#         lr = max(self.min_lr, min(self.max_lr, lr))\n",
    "#         return [lr for _ in self.optimizer.param_groups]\n",
    "\n",
    "# # Update optimizer and scheduler\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=1e-4)\n",
    "# scheduler = CosineWarmupWithBounds(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=int(0.2 * num_training_steps),\n",
    "#     num_training_steps=num_training_steps,\n",
    "#     num_cycles=NUM_CYCLES,\n",
    "#     max_lr=1e-4,\n",
    "#     min_lr=1e-5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvubkk67\u001b[0m (\u001b[33mvubkk67-hanoi-university-of-science-and-technology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vuda/Text-Summarization/Abstractive/wandb/run-20250510_123414-hiay6tgl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/hiay6tgl' target=\"_blank\">pegasus-custom-20250510-123413</a></strong> to <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/hiay6tgl' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/hiay6tgl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/hiay6tgl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f3a046f43b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights & Biases initialization\n",
    "wandb.init(\n",
    "    project=\"Finetune-Summarization\",\n",
    "    name=f\"pegasus-custom-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    config={\n",
    "        \"model\": \"Pegasus_custom\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"num_cycles\": NUM_CYCLES,\n",
    "        \"data_ratio\": FRAC_SAMPLE,\n",
    "        \"warm_up\": \"Cosine\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5476f94aae6d4d839ba62db3c601b53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae1fdde56c7473dba64dac39c125ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 1\n",
      "Epoch 01 | Train Loss: 8.9396 | Val Loss: 7.1121 | LR: 0.000005 | Time: 1672.77s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88afb201395344a5919736ca61c1b9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68568829c714577a6e628b6c8fd2c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 2\n",
      "Epoch 02 | Train Loss: 6.7329 | Val Loss: 6.4687 | LR: 0.000010 | Time: 1682.94s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53137c1a1ecf437995e06b60dba462ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e620cae2a24d6c98eead09e27160a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 3\n",
      "Epoch 03 | Train Loss: 6.2728 | Val Loss: 6.0639 | LR: 0.000015 | Time: 1653.50s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affb3f0e03bc4ad48c443496a82b5892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efda9785af3540698b8c68501f3562db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 4\n",
      "Epoch 04 | Train Loss: 5.9013 | Val Loss: 5.7434 | LR: 0.000020 | Time: 1650.86s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c093e695274e72b68e5b5e74322382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe7ee86fde54052aeeefb93f3e65b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 5\n",
      "Epoch 05 | Train Loss: 5.5898 | Val Loss: 5.5027 | LR: 0.000025 | Time: 1644.41s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51c3b3f3a024cc288e223edf1e4d5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1499fc1c5d24331adc5dbefeb17889f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 6\n",
      "Epoch 06 | Train Loss: 5.3127 | Val Loss: 5.2934 | LR: 0.000030 | Time: 1645.79s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522a057e02cc438095937520d60d85a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fe6ee0f0de4a10bc3436a2f9bb4df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 7\n",
      "Epoch 07 | Train Loss: 5.0478 | Val Loss: 5.1072 | LR: 0.000035 | Time: 1643.65s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3510c77528334ffb9411b535430b9440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1f25d58e0947aa9622fc136c2517b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 8\n",
      "Epoch 08 | Train Loss: 4.7777 | Val Loss: 4.9455 | LR: 0.000040 | Time: 1647.24s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de164034701482a9a2934a8324ae4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a622ed95bf3947e7a3445e11e9d7d609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 9\n",
      "Epoch 09 | Train Loss: 4.4917 | Val Loss: 4.8213 | LR: 0.000045 | Time: 1644.61s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f093d1f670c447eabb28d8a81b8c7dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a149d80ced04a0e9e22491afeee83eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 10\n",
      "Epoch 10 | Train Loss: 4.1942 | Val Loss: 4.6970 | LR: 0.000050 | Time: 1648.25s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75b103ddc0042709d6bc00f54408db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b7cc9130bb4f359acbf7cbac254e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 11\n",
      "Epoch 11 | Train Loss: 3.8764 | Val Loss: 4.6171 | LR: 0.000047 | Time: 1645.68s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46412c420f41404fb955e82e648a145a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4e28183af8499083a56a5badb54ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model to `fine_tuned_pegasus_custom` at epoch 12\n",
      "Epoch 12 | Train Loss: 3.5350 | Val Loss: 4.5965 | LR: 0.000040 | Time: 1646.25s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f935edcd5dfb4ce8a0b296371d7e0484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a83596d90244dabbc733ad813ea7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 3.2041 | Val Loss: 4.6016 | LR: 0.000029 | Time: 1710.94s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41defff3a2f04386be1d4c2f372d548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6735c968dec4e58964a0168034777da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 2.9029 | Val Loss: 4.6581 | LR: 0.000017 | Time: 1846.82s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd560457cec4eb8b07473c2005ef8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3320bb8fbd24418bbfb009b0d030ae2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 2.6682 | Val Loss: 4.6889 | LR: 0.000007 | Time: 1846.02s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04b8bf194f46e2a1b5c29aefb478b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78d1984c48f472880eed68016ddd8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 2.5207 | Val Loss: 4.7192 | LR: 0.000001 | Time: 1846.88s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0d380552c54e5ebe2e91cdce946f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Train]:   0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573087e9d5eb493e86d33cc834c1f804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 [Val]:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d72a08410e41329383a9eb13ed05f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.440 MB of 0.440 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td> █▆▅▄▄▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>lr</td><td>▂▂▃▄▄▅▆▇▇██▇▅▃▂▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▄▃▃▃▂▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>4.5965</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>2.46188</td></tr><tr><td>val_loss</td><td>4.72354</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pegasus-custom-20250510-123413</strong> at: <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/hiay6tgl' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization/runs/hiay6tgl</a><br/> View project at: <a href='https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization' target=\"_blank\">https://wandb.ai/vubkk67-hanoi-university-of-science-and-technology/Finetune-Summarization</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250510_123414-hiay6tgl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save best model and early stopping\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "wandb.watch(model)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(\"⚠️ Detected NaN loss. Skipping batch.\")\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # <--- CLIP\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    # W&B log\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"lr\": current_lr,\n",
    "        \"best_val_loss\": best_val_loss\n",
    "    })\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model.save_pretrained(save_dir)\n",
    "        tokenizer.save_pretrained(save_dir)\n",
    "        print(f\"Saved best model to `{save_dir}` at epoch {epoch+1}\")\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # Early stopping\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"LR: {current_lr:.6f} | \"\n",
    "        f\"Time: {time.time() - start_time:.2f}s\"\n",
    "    )\n",
    "\n",
    "# W&B end\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")\n",
    "# model = PegasusForConditionalGeneration.from_pretrained(save_dir).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998809fcff9b49eaab8a8117742a0668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating summaries:   0%|          | 0/1056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74018/1907396855.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"input_ids\": torch.tensor(input_ids), \"attention_mask\": torch.tensor(attention_mask), \"decoder_input_ids\": torch.tensor(decoder_input_ids), \"decoder_attention_mask\": torch.tensor(decoder_attention_mask), \"labels\": torch.tensor(labels)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File has been saved at: ../dataft/test_pred_5.csv\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(tqdm(test_loader, desc=\"Generating summaries\")):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        output_ids = model.generate(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            max_length=MAX_LENGTH_SUMMARY,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        batch_preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        predictions.extend(batch_preds)\n",
    "\n",
    "test_sample = test_df.iloc[:len(predictions)].copy()\n",
    "test_sample[\"predicted_summary\"] = predictions\n",
    "test_sample.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ File has been saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.read_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>predicted_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Florida bus passenger was arrested for throw...</td>\n",
       "      <td>Joel Parker, 33, was riding the bus in St John...</td>\n",
       "      <td>d Joel Parker, 33, and threw a bar at St. Park...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aston Villa may be able to sign Cordoba strike...</td>\n",
       "      <td>Aston Villa have held talks over Cordoba strik...</td>\n",
       "      <td>first-one could sign for £2.5million this seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A South Carolina mother of four died over the ...</td>\n",
       "      <td>Adam Leheup ran Fitness 535 in Columbia, South...</td>\n",
       "      <td>ing, a mother of a mother-of-four and her brot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A playground in Tokyo has been found to have d...</td>\n",
       "      <td>Soil underneath a slide in the park showed ext...</td>\n",
       "      <td>ing from high levels of high levels of radiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A lonely shepherd has been found dead alongsid...</td>\n",
       "      <td>Body of Jose Alberto, 58, discovered at home i...</td>\n",
       "      <td>s were found dead in San Josep, 58, two young ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Four years after signing for Arsenal, Wellingt...</td>\n",
       "      <td>Wellington Silva signed for Arsenal in 2011 fo...</td>\n",
       "      <td>ing has been granted his passport for £3.5mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joey Barton has urged QPR to use their win ove...</td>\n",
       "      <td>Queens Park Rangers strode to a 4-1 victory ag...</td>\n",
       "      <td>ing's side beat QPR 4-1 over West Brom . The 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>An Indian woman who holds several awards for t...</td>\n",
       "      <td>Smita Srivastava currently holds record for lo...</td>\n",
       "      <td>one of the best hair for her hair . She is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Drilling threes on the buzzer is all good as f...</td>\n",
       "      <td>LeBron James posted an unhappy picture at the ...</td>\n",
       "      <td>ing James James is one of the Cleveland Bulls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A teenager killed by police in Illinois on Sat...</td>\n",
       "      <td>Justus Howell, 17, was running from scene of a...</td>\n",
       "      <td>. Howell revealed he was shot twice for one sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            articles  \\\n",
       "0  A Florida bus passenger was arrested for throw...   \n",
       "1  Aston Villa may be able to sign Cordoba strike...   \n",
       "2  A South Carolina mother of four died over the ...   \n",
       "3  A playground in Tokyo has been found to have d...   \n",
       "4  A lonely shepherd has been found dead alongsid...   \n",
       "5  Four years after signing for Arsenal, Wellingt...   \n",
       "6  Joey Barton has urged QPR to use their win ove...   \n",
       "7  An Indian woman who holds several awards for t...   \n",
       "8  Drilling threes on the buzzer is all good as f...   \n",
       "9  A teenager killed by police in Illinois on Sat...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Joel Parker, 33, was riding the bus in St John...   \n",
       "1  Aston Villa have held talks over Cordoba strik...   \n",
       "2  Adam Leheup ran Fitness 535 in Columbia, South...   \n",
       "3  Soil underneath a slide in the park showed ext...   \n",
       "4  Body of Jose Alberto, 58, discovered at home i...   \n",
       "5  Wellington Silva signed for Arsenal in 2011 fo...   \n",
       "6  Queens Park Rangers strode to a 4-1 victory ag...   \n",
       "7  Smita Srivastava currently holds record for lo...   \n",
       "8  LeBron James posted an unhappy picture at the ...   \n",
       "9  Justus Howell, 17, was running from scene of a...   \n",
       "\n",
       "                                   predicted_summary  \n",
       "0  d Joel Parker, 33, and threw a bar at St. Park...  \n",
       "1  first-one could sign for £2.5million this seas...  \n",
       "2  ing, a mother of a mother-of-four and her brot...  \n",
       "3  ing from high levels of high levels of radiati...  \n",
       "4  s were found dead in San Josep, 58, two young ...  \n",
       "5  ing has been granted his passport for £3.5mill...  \n",
       "6  ing's side beat QPR 4-1 over West Brom . The 1...  \n",
       "7  one of the best hair for her hair . She is the...  \n",
       "8  ing James James is one of the Cleveland Bulls ...  \n",
       "9  . Howell revealed he was shot twice for one sh...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_pred[[\"articles\",\"summaries\", \"predicted_summary\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores:\n",
      "ROUGE-1: 0.2858\n",
      "ROUGE-2: 0.0646\n",
      "ROUGE-L: 0.2656\n"
     ]
    }
   ],
   "source": [
    "# Tính điểm ROUGE\n",
    "if \"summaries\" in test_pred.columns:\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(predictions, test_sample[\"summaries\"].tolist(), avg=True)\n",
    "\n",
    "    print(\"ROUGE scores:\")\n",
    "    print(f\"ROUGE-1: {scores['rouge-1']['f']:.4f}\")\n",
    "    print(f\"ROUGE-2: {scores['rouge-2']['f']:.4f}\")\n",
    "    print(f\"ROUGE-L: {scores['rouge-l']['f']:.4f}\")\n",
    "else:\n",
    "    print(\"⚠️ Không tìm thấy cột 'summaries' để tính ROUGE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
